# Goal_Dynamics_Analysis.py
# This script is designed to work with logs conceptually generated by prototype_logger.py,
# as outlined in PiaAGI_Research_Tools/PiaAVT/examples/conceptual_piase_log_generation.md.

import json
import time
import argparse # Added for command-line arguments
from collections import defaultdict

def load_and_parse_log_data_jsonl(log_file_path: str) -> list:
    """
    Reads a JSONL file, parses each line into a dictionary, and returns a list of these dictionaries.
    Handles potential FileNotFoundError and json.JSONDecodeError.
    Skips empty lines. Sorts entries by timestamp.

    Args:
        log_file_path (str): The path to the JSONL log file.

    Returns:
        list: A list of log entry dictionaries, sorted by 'timestamp'.
              Returns an empty list if the file is not found, parsing fails, or the file is empty.
    """
    parsed_logs = []
    try:
        with open(log_file_path, 'r') as f:
            for line_number, line in enumerate(f, 1):
                stripped_line = line.strip()
                if not stripped_line:  # Skip empty lines
                    continue
                try:
                    parsed_logs.append(json.loads(stripped_line))
                except json.JSONDecodeError as e:
                    print(f"Error decoding JSON from line {line_number} in {log_file_path}: {stripped_line} - {e}")
        # Sort by timestamp to ensure chronological processing
        parsed_logs.sort(key=lambda x: x.get("timestamp", float('inf'))) # float('inf') for entries missing timestamp
    except FileNotFoundError:
        print(f"Error: Log file not found at {log_file_path}")
        return []
    except Exception as e:
        print(f"An unexpected error occurred during log file processing: {e}")
        return []
    return parsed_logs

def analyze_goal_lifecycles(parsed_logs: list) -> dict:
    """
    Analyzes parsed log data to reconstruct the lifecycle of each goal.

    Args:
        parsed_logs (list): A list of log entry dictionaries, sorted by timestamp.

    Returns:
        dict: A dictionary where keys are goal_ids and values are dictionaries
              containing the reconstructed lifecycle information for each goal.
              Example structure:
              {
                  "G001": {
                      "description": "Explore novel object A",
                      "type": "INTRINSIC_CURIOSITY",
                      "creation_time": 1678886400.5,
                      "current_priority": 0.75,
                      "priority_history": [{"timestamp": ..., "priority": ...}, ...],
                      "state_history": [{"timestamp": ..., "state": ..., "reason": ...}, ...],
                      "outcome": "ACHIEVED",
                      "end_time": 1678886410.2,
                      "duration_seconds": 9.7
                  }, ...
              }
    """
    # Using defaultdict to easily initialize new goal entries
    # In a real implementation, more robust data structures might be used.
    goals_data = defaultdict(lambda: {
        "priority_history": [],
        "state_history": [],
        "events_processed": 0 # For tracking if any event related to this goal was processed
    })

    for entry in parsed_logs:
        event_type = entry.get("event_type")
        event_data = entry.get("event_data", {})
        goal_id = event_data.get("goal_id")
        timestamp = entry.get("timestamp")

        if not goal_id or timestamp is None:
            continue # Skip entries without goal_id or timestamp

        current_goal = goals_data[goal_id]
        current_goal["events_processed"] += 1


        if event_type == "GOAL_CREATED":
            current_goal["goal_id"] = goal_id
            current_goal["description"] = event_data.get("description", "N/A")
            current_goal["type"] = event_data.get("type", "UNKNOWN")
            current_goal["creation_time"] = timestamp
            initial_priority = event_data.get("initial_priority", 0.0) 
            current_goal["initial_priority_value"] = initial_priority # Store initial priority
            current_goal["current_priority"] = initial_priority
            current_goal["priority_history"].append({"timestamp": timestamp, "priority": initial_priority})
            current_goal["state_history"].append({"timestamp": timestamp, "state": "CREATED/PENDING"})
            current_goal["source_trigger_event_id"] = event_data.get("source_trigger_event_id")
            current_goal["urgency"] = event_data.get("urgency") 
            current_goal["deadline"] = event_data.get("deadline")
            # Initialize new fields
            current_goal["priority_change_count"] = 0
            current_goal["total_priority_change_magnitude"] = 0.0 # Sum of absolute changes
            current_goal["final_failure_reason"] = None


        elif event_type == "GOAL_ACTIVATED":
            # This event signifies a more explicit transition to an active, pursued state.
            # It might follow GOAL_CREATED or a GOAL_STATE_CHANGED to PENDING/SUSPENDED.
            current_goal["state_history"].append({
                "timestamp": timestamp, 
                "state": "ACTIVE", # Explicitly mark as ACTIVE
                "reason": f"Activated: {event_data.get('reason', 'N/A')}"
            })
            current_goal["current_state"] = "ACTIVE"
            if "first_activation_time" not in current_goal:
                 current_goal["first_activation_time"] = timestamp
        
        elif event_type == "GOAL_DEACTIVATED":
            # Signifies goal is no longer being actively pursued but not necessarily terminal.
            # Could be due to preemption, resource unavailability, etc.
            current_goal["state_history"].append({
                "timestamp": timestamp,
                "state": "INACTIVE/SUSPENDED", # A more generic inactive state
                "reason": f"Deactivated: {event_data.get('reason', 'N/A')}"
            })
            current_goal["current_state"] = "INACTIVE/SUSPENDED"

        elif event_type == "GOAL_STATE_CHANGED":
            new_state = event_data.get("new_state")
            reason = event_data.get("reason")
            current_goal["state_history"].append({"timestamp": timestamp, "state": new_state, "reason": reason})
            current_goal["current_state"] = new_state # Keep track of latest state
            
            # If GOAL_STATE_CHANGED indicates activation and we haven't logged it via GOAL_ACTIVATED
            if new_state == "ACTIVE" and "first_activation_time" not in current_goal:
                current_goal["first_activation_time"] = timestamp

            if new_state in ["ACHIEVED", "FAILED", "ABANDONED", "INVALIDATED"]: # Terminal states
                current_goal["outcome"] = new_state
                current_goal["end_time"] = timestamp
            if "creation_time" in current_goal:
                    current_goal["duration_seconds"] = round(timestamp - current_goal["creation_time"], 2)
                    if "first_activation_time" in current_goal and current_goal["first_activation_time"] <= timestamp :
                        current_goal["active_duration_seconds"] = round(timestamp - current_goal["first_activation_time"], 2)
            if new_state in ["FAILED", "BLOCKED"] and reason: # Store failure/blockage reason
                current_goal["final_failure_reason"] = reason


        elif event_type == "GOAL_PRIORITY_UPDATED":
            new_priority = event_data.get("new_priority")
            old_priority = event_data.get("old_priority", current_goal.get("current_priority")) # Use last known if old_priority not in event

            current_goal["current_priority"] = new_priority
            current_goal["priority_history"].append({
                "timestamp": timestamp,
                "priority": new_priority,
                "old_priority": old_priority,
                "reason": event_data.get("reason")
            })
            # Update priority change stats
            if old_priority is not None and new_priority is not None: # Ensure both exist
                current_goal["priority_change_count"] = current_goal.get("priority_change_count", 0) + 1
                current_goal["total_priority_change_magnitude"] = current_goal.get("total_priority_change_magnitude", 0.0) + abs(new_priority - old_priority)


    # After processing all logs, calculate average priority change magnitude for each goal
    for goal_id, data in goals_data.items():
        if data.get("priority_change_count", 0) > 0:
            data["avg_priority_change_magnitude"] = round(
                data["total_priority_change_magnitude"] / data["priority_change_count"],
                3 # Round to 3 decimal places
            )
        else:
            data["avg_priority_change_magnitude"] = 0.0
        # Ensure all goals have these fields, even if no priority updates occurred
        data.setdefault("priority_change_count", 0)
        data.setdefault("final_failure_reason", None)
        data.setdefault("initial_priority_value", data.get("current_priority")) # Fallback if GOAL_CREATED was missed


    return dict(goals_data)

def generate_summary_report(analyzed_goals_data: dict):
    """
    Generates and prints a conceptual summary report from the analyzed goal data.

    Args:
        analyzed_goals_data (dict): The output from analyze_goal_lifecycles.
    """
    if not analyzed_goals_data:
        print("No goal data to analyze.")
        return

    total_goals = len(analyzed_goals_data)
    achieved_count = 0
    failed_count = 0
    suspended_count = 0
    active_count = 0 # Or any other non-terminal state

    total_duration_completed = 0
    num_completed_goals_for_duration_avg = 0

    goals_by_type = defaultdict(lambda: {"count": 0, "achieved": 0, "failed": 0, "total_duration": 0, "num_for_duration": 0})
    failure_reasons_summary = defaultdict(int)
    priority_changes_total_count = 0
    goals_with_priority_changes = 0

    # For success rates by initial priority
    # Define priority bands (example, assuming priorities are 0-10 from GoalUpdatePayload, or 0-1 for intrinsic intensity based)
    # For this example, let's assume initial_priority_value is on a 0-10 scale for extrinsic,
    # and intrinsic (intensity*10) also falls in this.
    # Note: The actual priority scale (e.g., 0-1, 0-100) and these bands might need adjustment
    # based on the actual range of priority values logged by the specific PiaAGI agent configuration.
    priority_bands = {
        "Low (0-3.5)": {"total": 0, "achieved": 0},
        "Medium (3.5-7.5)": {"total": 0, "achieved": 0},
        "High (7.5-10+)": {"total": 0, "achieved": 0}
    }

    print("\n--- Goal Dynamics Summary Report ---")
    print(f"Total unique goals identified: {total_goals}")

    for goal_id, data in analyzed_goals_data.items():
        if not data.get("events_processed"):
            print(f"Warning: Goal ID {goal_id} found but no relevant events processed. Initial data: {data}")
            continue

        goal_type = data.get("type", "UNKNOWN")
        goals_by_type[goal_type]["count"] += 1

        outcome = data.get("outcome")
        if outcome == "ACHIEVED":
            achieved_count += 1
            goals_by_type[goal_type]["achieved"] += 1
        elif outcome == "FAILED":
            failed_count += 1
            goals_by_type[goal_type]["failed"] += 1
            if data.get("final_failure_reason"):
                failure_reasons_summary[data["final_failure_reason"]] += 1
        elif data.get("current_state") == "SUSPENDED":
            suspended_count +=1
        elif data.get("current_state") == "ACTIVE":
            active_count += 1

        if "duration_seconds" in data: # For all terminal goals
            total_duration_completed += data["duration_seconds"]
            num_completed_goals_for_duration_avg +=1
            goals_by_type[goal_type]["total_duration"] += data["duration_seconds"]
            goals_by_type[goal_type]["num_for_duration"] +=1

        if data.get("priority_change_count", 0) > 0:
            priority_changes_total_count += data["priority_change_count"]
            goals_with_priority_changes += 1

        # Success rate by initial priority
        initial_prio = data.get("initial_priority_value")
        if initial_prio is not None:
            band = None
            if initial_prio <= 3.5: band = "Low (0-3.5)"
            elif initial_prio <= 7.5: band = "Medium (3.5-7.5)"
            else: band = "High (7.5-10+)"

            if band:
                priority_bands[band]["total"] += 1
                if outcome == "ACHIEVED":
                    priority_bands[band]["achieved"] += 1


    print(f"\nOutcomes:")
    print(f"  - Achieved: {achieved_count}")
    print(f"  - Failed:   {failed_count}")
    print(f"  - Suspended (currently): {suspended_count}")
    print(f"  - Active (currently):    {active_count}")


    if num_completed_goals_for_duration_avg > 0:
        avg_duration = round(total_duration_completed / num_completed_goals_for_duration_avg, 2)
        print(f"\nOverall average duration for completed (achieved/failed) goals: {avg_duration} seconds")
    else:
        print("\nNo goals completed to calculate overall average duration.")

    print("\n--- Goal Statistics by Type ---")
    for goal_type, type_data in goals_by_type.items():
        print(f"  Type: {goal_type}")
        print(f"    Total Count: {type_data['count']}")
        print(f"    Achieved: {type_data['achieved']}")
        print(f"    Failed: {type_data['failed']}")
        success_rate = (type_data['achieved'] / (type_data['achieved'] + type_data['failed'])) * 100 if (type_data['achieved'] + type_data['failed']) > 0 else 0
        print(f"    Success Rate: {success_rate:.2f}%")
        if type_data['num_for_duration'] > 0:
            avg_type_duration = round(type_data['total_duration'] / type_data['num_for_duration'], 2)
            print(f"    Avg Duration (completed): {avg_type_duration}s")
        else:
            print(f"    Avg Duration (completed): N/A (no completed goals of this type)")


    print("\n--- Priority Change Statistics ---")
    if goals_with_priority_changes > 0:
        avg_prio_changes = round(priority_changes_total_count / goals_with_priority_changes, 2)
        print(f"  Average priority changes per goal (for goals with changes): {avg_prio_changes}")
    else:
        print("  No priority changes recorded for any goal.")
    # Optionally, list goals with most changes (e.g., top 3)
    sorted_goals_by_prio_change = sorted(
        [data for data in analyzed_goals_data.values() if data.get("events_processed") and data.get("priority_change_count", 0) > 0],
        key=lambda x: x["priority_change_count"],
        reverse=True
    )
    if sorted_goals_by_prio_change:
        print("  Top goals by number of priority changes:")
        for goal_data in sorted_goals_by_prio_change[:3]: # Top 3
            print(f"    - ID: {goal_data['goal_id']}, Changes: {goal_data['priority_change_count']}, Avg Mag: {goal_data.get('avg_priority_change_magnitude', 'N/A'):.2f}")


    print("\n--- Common Failure/Blockage Reasons ---")
    if failure_reasons_summary:
        for reason, count in sorted(failure_reasons_summary.items(), key=lambda item: item[1], reverse=True):
            print(f"  - \"{reason}\": {count} times")
    else:
        print("  No specific failure/blockage reasons recorded or no failures.")

    print("\n--- Success Rates by Initial Priority Band ---")
    for band_name, data in priority_bands.items():
        if data["total"] > 0:
            rate = (data["achieved"] / data["total"]) * 100
            print(f"  {band_name}: {rate:.2f}% success rate ({data['achieved']}/{data['total']})")
        else:
            print(f"  {band_name}: N/A (0 goals in this band)")


    print("\n--- Example Goal Lifecycles ---") # Renamed for clarity
    # Print details for a couple of goals as examples
    example_goal_ids = list(analyzed_goals_data.keys())[:2] # Take first two goals
    for goal_id in example_goal_ids:
        if goal_id not in analyzed_goals_data or not analyzed_goals_data[goal_id].get("events_processed"):
            continue
        data = analyzed_goals_data[goal_id]
        print(f"\n  Goal ID: {data.get('goal_id', goal_id)}")
        print(f"\n  Goal ID: {data.get('goal_id', goal_id)}")
        print(f"    Description: {data.get('description', 'N/A')}")
        print(f"    Type: {data.get('type', 'N/A')}")
        print(f"    Creation Time: {data.get('creation_time', 'N/A')}")
        if "first_activation_time" in data:
            print(f"    First Activation Time: {data.get('first_activation_time')}")
        print(f"    Current Priority: {data.get('current_priority', 'N/A')}")
        print(f"    Outcome: {data.get('outcome', data.get('current_state', 'N/A'))}")
        if "duration_seconds" in data:
            print(f"    Total Duration (Creation to End): {data['duration_seconds']}s")
        if "active_duration_seconds" in data:
            print(f"    Active Duration (Activation to End): {data['active_duration_seconds']}s")
        if data.get("source_trigger_event_id"):
            print(f"    Source Trigger: {data.get('source_trigger_event_id')}")


        print("    State History:")
        for state_event in data.get("state_history", []):
            reason_str = f" (Reason: {state_event.get('reason')})" if state_event.get('reason') else ""
            print(f"      - {state_event.get('timestamp')}: {state_event.get('state')}{reason_str}")

        print("    Priority History:")
        for prio_event in data.get("priority_history", []):
            print(f"      - {prio_event.get('timestamp')}: Priority {prio_event.get('priority')}")

    print("\n--- End of Report ---")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Analyzes goal dynamics from PiaAVT JSONL log files.",
        epilog="Example: python Goal_Dynamics_Analysis.py /path/to/your/logfile.jsonl"
    )
    parser.add_argument(
        "log_file",
        help="Path to the JSONL log file to analyze."
    )
    args = parser.parse_args()

    if not args.log_file:
        parser.print_usage()
        print("Error: Log file path is required.")
        exit(1)

    print(f"Starting Goal Dynamics Analysis for log file: {args.log_file}...")

    parsed_logs = load_and_parse_log_data_jsonl(args.log_file)

    if parsed_logs:
        print(f"\nSuccessfully parsed {len(parsed_logs)} log entries from {args.log_file}.")
        analyzed_data = analyze_goal_lifecycles(parsed_logs)

        if analyzed_data:
            print(f"Successfully analyzed {len(analyzed_data)} unique goals.")
            generate_summary_report(analyzed_data)
        else:
            print("Analysis returned no data for the goals found in the logs.")
    else:
        print(f"Log parsing returned no data from {args.log_file}. Ensure the file exists, is not empty, and contains valid JSONL.")
