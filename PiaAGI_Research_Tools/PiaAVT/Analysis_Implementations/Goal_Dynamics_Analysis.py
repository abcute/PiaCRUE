# Goal_Dynamics_Analysis.py
# This script is designed to work with logs conceptually generated by prototype_logger.py,
# as outlined in PiaAGI_Research_Tools/PiaAVT/examples/conceptual_piase_log_generation.md.

import json
import time
import argparse # Added for command-line arguments
from collections import defaultdict

def load_and_parse_log_data_jsonl(log_file_path: str) -> list:
    """
    Reads a JSONL file, parses each line into a dictionary, and returns a list of these dictionaries.
    Handles potential FileNotFoundError and json.JSONDecodeError.
    Skips empty lines. Sorts entries by timestamp.

    Args:
        log_file_path (str): The path to the JSONL log file.

    Returns:
        list: A list of log entry dictionaries, sorted by 'timestamp'.
              Returns an empty list if the file is not found, parsing fails, or the file is empty.
    """
    parsed_logs = []
    try:
        with open(log_file_path, 'r') as f:
            for line_number, line in enumerate(f, 1):
                stripped_line = line.strip()
                if not stripped_line:  # Skip empty lines
                    continue
                try:
                    parsed_logs.append(json.loads(stripped_line))
                except json.JSONDecodeError as e:
                    print(f"Error decoding JSON from line {line_number} in {log_file_path}: {stripped_line} - {e}")
        # Sort by timestamp to ensure chronological processing
        parsed_logs.sort(key=lambda x: x.get("timestamp", float('inf'))) # float('inf') for entries missing timestamp
    except FileNotFoundError:
        print(f"Error: Log file not found at {log_file_path}")
        return []
    except Exception as e:
        print(f"An unexpected error occurred during log file processing: {e}")
        return []
    return parsed_logs

def analyze_goal_lifecycles(parsed_logs: list) -> dict:
    """
    Analyzes parsed log data to reconstruct the lifecycle of each goal.

    Args:
        parsed_logs (list): A list of log entry dictionaries, sorted by timestamp.

    Returns:
        dict: A dictionary where keys are goal_ids and values are dictionaries
              containing the reconstructed lifecycle information for each goal.
              Example structure:
              {
                  "G001": {
                      "description": "Explore novel object A",
                      "type": "INTRINSIC_CURIOSITY",
                      "creation_time": 1678886400.5,
                      "current_priority": 0.75,
                      "priority_history": [{"timestamp": ..., "priority": ...}, ...],
                      "state_history": [{"timestamp": ..., "state": ..., "reason": ...}, ...],
                      "outcome": "ACHIEVED",
                      "end_time": 1678886410.2,
                      "duration_seconds": 9.7
                  }, ...
              }
    """
    # Using defaultdict to easily initialize new goal entries
    # In a real implementation, more robust data structures might be used.
    goals_data = defaultdict(lambda: {
        "priority_history": [],
        "state_history": [],
        "events_processed": 0 # For tracking if any event related to this goal was processed
    })

    for entry in parsed_logs:
        event_type = entry.get("event_type")
        event_data = entry.get("event_data", {})
        goal_id = event_data.get("goal_id")
        timestamp = entry.get("timestamp")

        if not goal_id or timestamp is None:
            continue # Skip entries without goal_id or timestamp

        current_goal = goals_data[goal_id]
        current_goal["events_processed"] += 1


        if event_type == "GOAL_CREATED": # Updated event type
            current_goal["goal_id"] = goal_id # Store it explicitly
            current_goal["description"] = event_data.get("description", "N/A")
            current_goal["type"] = event_data.get("type", "UNKNOWN")
            current_goal["creation_time"] = timestamp
            # Align with prototype_logger.py and conceptual_piase_log_generation.md
            initial_priority = event_data.get("initial_priority", 0.0) 
            current_goal["current_priority"] = initial_priority
            current_goal["priority_history"].append({"timestamp": timestamp, "priority": initial_priority})
            # Initial state is implicitly PENDING or as per agent's internal logic upon creation
            current_goal["state_history"].append({"timestamp": timestamp, "state": "CREATED/PENDING"})
            current_goal["source_trigger_event_id"] = event_data.get("source_trigger_event_id")
            # Store other relevant fields from GOAL_CREATED if needed for analysis
            current_goal["urgency"] = event_data.get("urgency") 
            current_goal["deadline"] = event_data.get("deadline")

        elif event_type == "GOAL_ACTIVATED":
            # This event signifies a more explicit transition to an active, pursued state.
            # It might follow GOAL_CREATED or a GOAL_STATE_CHANGED to PENDING/SUSPENDED.
            current_goal["state_history"].append({
                "timestamp": timestamp, 
                "state": "ACTIVE", # Explicitly mark as ACTIVE
                "reason": f"Activated: {event_data.get('reason', 'N/A')}"
            })
            current_goal["current_state"] = "ACTIVE"
            if "first_activation_time" not in current_goal:
                 current_goal["first_activation_time"] = timestamp
        
        elif event_type == "GOAL_DEACTIVATED":
            # Signifies goal is no longer being actively pursued but not necessarily terminal.
            # Could be due to preemption, resource unavailability, etc.
            current_goal["state_history"].append({
                "timestamp": timestamp,
                "state": "INACTIVE/SUSPENDED", # A more generic inactive state
                "reason": f"Deactivated: {event_data.get('reason', 'N/A')}"
            })
            current_goal["current_state"] = "INACTIVE/SUSPENDED"

        elif event_type == "GOAL_STATE_CHANGED":
            new_state = event_data.get("new_state")
            reason = event_data.get("reason")
            current_goal["state_history"].append({"timestamp": timestamp, "state": new_state, "reason": reason})
            current_goal["current_state"] = new_state # Keep track of latest state
            
            # If GOAL_STATE_CHANGED indicates activation and we haven't logged it via GOAL_ACTIVATED
            if new_state == "ACTIVE" and "first_activation_time" not in current_goal:
                current_goal["first_activation_time"] = timestamp

            if new_state in ["ACHIEVED", "FAILED", "ABANDONED", "INVALIDATED"]: # Terminal states
                current_goal["outcome"] = new_state
                current_goal["end_time"] = timestamp
                if "creation_time" in current_goal: # Ensure goal was created
                    current_goal["duration_seconds"] = round(timestamp - current_goal["creation_time"], 2)
                    if "first_activation_time" in current_goal and current_goal["first_activation_time"] <= timestamp :
                        current_goal["active_duration_seconds"] = round(timestamp - current_goal["first_activation_time"], 2)


        elif event_type == "GOAL_PRIORITY_UPDATED":
            new_priority = event_data.get("new_priority")
            current_goal["current_priority"] = new_priority
            current_goal["priority_history"].append({
                "timestamp": timestamp,
                "priority": new_priority,
                "old_priority": event_data.get("old_priority"),
                "reason": event_data.get("reason")
            })

        # Ensure state_history and priority_history are sorted if logs weren't perfectly ordered for a given goal_id (though initial sort helps)
        # For this conceptual implementation, we assume chronological processing is sufficient after initial sort.

    return dict(goals_data) # Convert back to regular dict for output

def generate_summary_report(analyzed_goals_data: dict):
    """
    Generates and prints a conceptual summary report from the analyzed goal data.

    Args:
        analyzed_goals_data (dict): The output from analyze_goal_lifecycles.
    """
    if not analyzed_goals_data:
        print("No goal data to analyze.")
        return

    total_goals = len(analyzed_goals_data)
    achieved_count = 0
    failed_count = 0
    suspended_count = 0
    active_count = 0 # Or any other non-terminal state

    total_duration_completed = 0
    num_completed_goals_for_duration_avg = 0

    goals_by_type = defaultdict(int)

    print("\n--- Goal Dynamics Summary Report ---")
    print(f"Total unique goals identified: {total_goals}")

    for goal_id, data in analyzed_goals_data.items():
        if not data.get("events_processed"): # Skip if no events were processed for this goal_id
            print(f"Warning: Goal ID {goal_id} found but no relevant events processed. Initial data: {data}")
            continue

        goals_by_type[data.get("type", "UNKNOWN")] += 1

        outcome = data.get("outcome")
        if outcome == "ACHIEVED":
            achieved_count += 1
        elif outcome == "FAILED":
            failed_count += 1
        elif data.get("current_state") == "SUSPENDED": # Check current state if no terminal outcome
            suspended_count +=1
        elif data.get("current_state") == "ACTIVE": # Check current state
            active_count += 1
        # (Add more states as needed)

        if "duration_seconds" in data:
            total_duration_completed += data["duration_seconds"]
            num_completed_goals_for_duration_avg +=1

    print(f"\nOutcomes:")
    print(f"  - Achieved: {achieved_count}")
    print(f"  - Failed:   {failed_count}")
    print(f"  - Suspended (currently): {suspended_count}") # Based on last known state if not terminal
    print(f"  - Active (currently):    {active_count}") # Based on last known state if not terminal


    if num_completed_goals_for_duration_avg > 0:
        avg_duration = round(total_duration_completed / num_completed_goals_for_duration_avg, 2)
        print(f"\nAverage duration for completed (achieved/failed) goals: {avg_duration} seconds")
    else:
        print("\nNo goals completed to calculate average duration.")

    print("\nGoals by Type:")
    for goal_type, count in goals_by_type.items():
        print(f"  - {goal_type}: {count}")

    print("\nExample Goal Lifecycles (Conceptual):")
    # Print details for a couple of goals as examples
    example_goal_ids = list(analyzed_goals_data.keys())[:2] # Take first two goals
    for goal_id in example_goal_ids:
        if goal_id not in analyzed_goals_data or not analyzed_goals_data[goal_id].get("events_processed"):
            continue
        data = analyzed_goals_data[goal_id]
        print(f"\n  Goal ID: {data.get('goal_id', goal_id)}")
        print(f"\n  Goal ID: {data.get('goal_id', goal_id)}")
        print(f"    Description: {data.get('description', 'N/A')}")
        print(f"    Type: {data.get('type', 'N/A')}")
        print(f"    Creation Time: {data.get('creation_time', 'N/A')}")
        if "first_activation_time" in data:
            print(f"    First Activation Time: {data.get('first_activation_time')}")
        print(f"    Current Priority: {data.get('current_priority', 'N/A')}")
        print(f"    Outcome: {data.get('outcome', data.get('current_state', 'N/A'))}")
        if "duration_seconds" in data:
            print(f"    Total Duration (Creation to End): {data['duration_seconds']}s")
        if "active_duration_seconds" in data:
            print(f"    Active Duration (Activation to End): {data['active_duration_seconds']}s")
        if data.get("source_trigger_event_id"):
            print(f"    Source Trigger: {data.get('source_trigger_event_id')}")


        print("    State History:")
        for state_event in data.get("state_history", []):
            reason_str = f" (Reason: {state_event.get('reason')})" if state_event.get('reason') else ""
            print(f"      - {state_event.get('timestamp')}: {state_event.get('state')}{reason_str}")

        print("    Priority History:")
        for prio_event in data.get("priority_history", []):
            print(f"      - {prio_event.get('timestamp')}: Priority {prio_event.get('priority')}")

    print("\n--- End of Report ---")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Analyzes goal dynamics from PiaAVT JSONL log files.",
        epilog="Example: python Goal_Dynamics_Analysis.py /path/to/your/logfile.jsonl"
    )
    parser.add_argument(
        "log_file",
        help="Path to the JSONL log file to analyze."
    )
    args = parser.parse_args()

    if not args.log_file:
        parser.print_usage()
        print("Error: Log file path is required.")
        exit(1)

    print(f"Starting Goal Dynamics Analysis for log file: {args.log_file}...")

    parsed_logs = load_and_parse_log_data_jsonl(args.log_file)

    if parsed_logs:
        print(f"\nSuccessfully parsed {len(parsed_logs)} log entries from {args.log_file}.")
        analyzed_data = analyze_goal_lifecycles(parsed_logs)

        if analyzed_data:
            print(f"Successfully analyzed {len(analyzed_data)} unique goals.")
            generate_summary_report(analyzed_data)
        else:
            print("Analysis returned no data for the goals found in the logs.")
    else:
        print(f"Log parsing returned no data from {args.log_file}. Ensure the file exists, is not empty, and contains valid JSONL.")
