# Social Dialogue Sandbox Environment: Design Specification

**Document Version:** 1.0
**Date:** 2024-08-06
**Author:** PiaAGI Project Contributors (Generated by Jules)
**Status:** Draft

## 1. Introduction and Purpose

*   **Purpose:** Define the core purpose of the Social Dialogue Sandbox. It should facilitate research into advanced AI social interaction capabilities, including:
    *   Theory of Mind (ToM) development and application.
    *   Nuanced natural language communication (comprehension and generation).
    *   Emotional expression recognition and generation by the agent.
    *   Social reasoning and strategy.
    *   Testing and refining the PiaAGI agent's Communication Module, ToM Module, Emotion Module, and Self-Model in social contexts.
*   **Scope:** A simulated environment for turn-based dialogues between a PiaAGI agent and one or more simulated interactors (NPCs). Future extensions could include human-in-the-loop participation.

## 2. Core Components and State Representation

### 2.1. Dialogue State
*   **Dialogue History:** A chronological log of utterances, including speaker ID, utterance text, timestamp, and potentially conceptual non-verbal cues or emotional tone (if expressed/detected). (Current implementation: `List[Dict[str, str]]` for speaker_id, utterance).
*   **Turn Management:** Current turn holder ID, turn number. (Current implementation: `turn_index`, `current_turn_holder`).
*   **Dialogue Topic/Context:** Current subject of conversation, overall scenario goals. (Current implementation: `dialogue_config['topic']`).
*   **Max Turns/Termination Conditions:** Conditions for ending the dialogue. (Current implementation: `dialogue_config['max_turns']`, keyword detection).

### 2.2. Participant Representation (PiaAGI Agent and NPCs)
*   **Agent IDs:** List of all unique participant identifiers.
*   **NPC Profiles (`SimulatedInteractorProfile` in current code):**
    *   `interactor_id`: Unique ID.
    *   **Personality Traits (Conceptual Extension):** Parameters defining NPC personality (e.g., Big Five traits) influencing response style, emotional baseline, and goals. (Currently not implemented).
    *   **Emotional State (Conceptual Extension):** Internal emotional state of the NPC (e.g., valence, arousal, specific emotion type), which can change based on dialogue and influence responses. (Currently not implemented beyond response rules).
    *   **Goals/Intentions (Conceptual Extension):** Underlying goals the NPC is trying to achieve in the dialogue (e.g., persuade, inform, build rapport, hide information). (Currently not implemented).
    *   **Knowledge Base (Conceptual Extension):** A simple knowledge base or set of beliefs for the NPC. (Currently not implemented).
    *   **Response Logic:** (Currently `response_rules` and `default_response`).
        *   **Future:** Could be more sophisticated, e.g., simple LLM calls (if API available via config), state machines, or more complex rule engines based on its personality, emotion, and goals.

## 3. Perception Data Provided to Agent

*   **Primary Percept:** The last utterance made by the other participant(s). (Current implementation: `TextualPercept` with last utterance).
*   **Speaker ID:** Identifier of who made the last utterance. (Current implementation: `TextualPercept.source`).
*   **Turn Information:** Indication of whose turn it is, and if it's the agent's turn. (Current implementation: `custom_sensor_data.current_turn_holder`, `is_my_turn`).
*   **Dialogue Context:**
    *   Topic of conversation. (Current implementation: `custom_sensor_data.dialogue_topic`).
    *   List of participants. (Current implementation: `custom_sensor_data.participants`).
    *   Short dialogue history preview. (Current implementation: `custom_sensor_data.dialogue_history_preview`).
*   **Conceptual Non-Verbal Cues (Future Extension):**
    *   Simulated emotional tone of the last utterance (e.g., "happy," "frustrated," "neutral").
    *   Conceptual indicators of engagement, confusion, etc.
    *   These would be added to `PerceptionData.custom_sensor_data` or as new structured percept types.

## 4. Action Space for Agent

*   **`speak(utterance: str)`:** Agent provides a textual utterance. (Current implementation).
*   **`listen()`:** Agent explicitly passes its turn, choosing to observe. (Current implementation).
*   **Conceptual Future Actions:**
    *   `express_emotion(emotion_type: str, intensity: float)`: Agent conceptually expresses an emotion, which could influence NPC state and future responses.
    *   `query_npc_state(npc_id: str, state_aspect: str)`: Agent attempts to gather information about an NPC's internal state (e.g., "goal," "mood"). The environment would decide if/how to answer based on NPC profile.
    *   `propose_action(action_description: str)`: For collaborative scenarios, agent proposes a joint action.
    *   `change_topic(new_topic: str)`: Agent attempts to shift the conversation.

## 5. Environment Dynamics

### 5.1. Turn Progression
*   Strict turn-taking enforced by the environment. (Current implementation).
*   If an NPC's turn follows an agent's action, the NPC generates a response within the same `step` call that processed the agent's action. (Current implementation).

### 5.2. NPC Response Generation
*   **Current:** Simple keyword-matching rules (`SimulatedInteractorProfile`).
*   **Future Enhancements:**
    *   **Stateful NPCs:** NPC responses influenced by their internal (simulated) emotional state, personality, and goals.
    *   **LLM-based NPCs:** Option to configure NPCs to call an external LLM API for response generation, given a prompt constructed from dialogue history and NPC profile. (Requires API key management by user).
    *   **Adaptive NPCs:** NPCs whose goals or emotional states change based on the PiaAGI agent's utterances and expressed emotions.

### 5.3. Dialogue State Updates
*   Dialogue history is appended with each "speak" action.
*   NPC internal states (conceptual) would be updated based on interactions.

## 6. Scenario Definition

Scenarios for the Social Dialogue Sandbox should be configurable to allow for diverse research setups.
*   **Parameters for `SocialDialogueSandbox` constructor:**
    *   `dialogue_config`: Topic, max_turns, potentially other global settings like dialogue goals for the overall interaction. (Current implementation: `topic`, `max_turns`).
    *   `agent_ids`: List of all participants. (Current implementation).
    *   `simulated_interactor_configs`: Dictionary mapping NPC IDs to their configurations.
        *   **Current:** `response_rules`, `default_response`.
        *   **Future:** NPC personality profiles, initial emotional states, specific goals for the dialogue, simple knowledge bases.
*   **Example Scenario Setups:**
    *   **Persuasion Task:** PiaAGI agent needs to persuade an NPC with a specific personality and goal.
    *   **Conflict Resolution:** PiaAGI agent mediates a simulated conflict between two NPCs.
    *   **Empathetic Support:** PiaAGI agent needs to provide support to an NPC expressing distress.
    *   **Information Extraction:** PiaAGI agent needs to elicit specific information from a reluctant or secretive NPC.
    *   **Theory of Mind Test:** Scenarios designed to test specific ToM capabilities, like understanding false beliefs or intentions of NPCs.

## 7. Future Development and Extensions

*   Human-in-the-loop: Allow a human to take the role of one of the interactors.
*   More sophisticated NPC models (e.g., using small local LLMs or more complex BDI-like architectures).
*   Integration with PiaAVT for logging detailed social interaction metrics (e.g., turn-taking patterns, sentiment arcs, goal achievement rates in dialogue).
*   Richer non-verbal cue system.
*   Group dialogues with multiple NPCs and/or PiaAGI agents.

This design document provides a blueprint for the continued development of the Social Dialogue Sandbox, aiming to make it a valuable tool for PiaAGI research.
