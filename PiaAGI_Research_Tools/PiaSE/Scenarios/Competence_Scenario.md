<!-- PiaAGI Scenario Document -->
# Scenario: Competence in the "Adaptive Pathfinding Challenge"

**Document Version:** 1.0
**Date:** November 23, 2024
**Author:** PiaAGI Project Contributors (Generated by Jules)
**Status:** Conceptual Draft

## 1. Scenario Title

Competence in the "Adaptive Pathfinding Challenge"

## 2. Objective

To observe and evaluate the PiaAGI agent's competence-driven behavior, including skill improvement through practice, persistence in the face of failure, and preference for appropriately challenging tasks. This scenario aims to test the functionality of the 'Competence and Mastery' intrinsic motivation model.

## 3. Environment Description

*   **Type:** Dynamic 2D Grid World or a system presenting a series of discrete pathfinding puzzle instances.
*   **Setup:**
    *   A "Puzzle Hub" or interface where the agent can request or be assigned pathfinding tasks.
    *   Each puzzle is a grid (e.g., varying from 5x5 to 20x20) with a defined start cell, an end (goal) cell, and various obstacle cells.
*   **Difficulty Adjustment:**
    *   Puzzles are categorized by difficulty (e.g., Level 1 to 10, or "Easy," "Medium," "Hard").
    *   Difficulty can be determined by grid size, obstacle density, complexity of the optimal path (e.g., number of turns), or presence of dynamic elements (e.g., temporarily blocking paths, if advanced).
    *   The environment can (optionally) adaptively offer puzzles based on the agent's recent performance, aiming to keep tasks within the agent's Zone of Proximal Development (ZPD).
*   **Mechanisms:**
    *   **Task Presentation:** Agent can `request_puzzle(difficulty_level)` or be assigned a puzzle. The environment provides the puzzle parameters (grid dimensions, start/goal locations, obstacle map) as perception data.
    *   **Solution Submission:** Agent submits its proposed solution, typically as a sequence of moves (e.g., `submit_path(["UP", "RIGHT", "RIGHT", "DOWN"])`).
    *   **Feedback Provision:** After a solution submission (or timeout), the environment provides:
        *   `status`: "SUCCESS" or "FAILURE" (e.g., reached goal, hit obstacle, invalid path).
        *   `performance_metrics`: If successful, path length, time taken (steps). If failed, reason for failure.
        *   (Optional) Scaffolding: Hints or partial solutions if the agent is stuck and scaffolding mechanisms are enabled for the current developmental stage.

## 4. Agent Configuration

*   **Initial Skill Levels (`SelfModel.CapabilityInventory`):**
    *   Basic navigation skills (e.g., `execute_move <direction>`) at a "Developing" proficiency.
    *   Pathfinding/planning skill (e.g., `generate_plan_to_target`) at a "Novice" or low "Developing" proficiency.
    *   (Optional) Meta-cognitive skill: `assess_task_difficulty` at "Novice".
*   **Motivational Bias (PiaPES Prompt Configuration):**
    *   The agent's initial prompt should configure its `CognitiveModuleConfiguration` for a high drive for competence.
    *   Example: `MotivationalBias.biases = {"INTRINSIC_COMPETENCE_FACTOR": 0.85}`.
    *   Personality (within `PersonalityConfig`): High `OCEAN_Conscientiousness` (e.g., > 0.7) and moderate `OCEAN_Openness`.
*   **Initial Goals (Motivational System):**
    *   Primary active goal: An intrinsic goal like `(goal_id: "IMPROVE_PATHFINDING_001", type: "INTRINSIC_COMPETENCE", description: "Improve pathfinding skill and solve puzzles efficiently", priority: high)`.
    *   (Optional) A general extrinsic goal like "Successfully complete 5 puzzles offered by the Puzzle Hub."

## 5. Competence Triggers and Observable Behaviors

*   **Expected Triggers for Competence Drive:**
    *   `TASK_OUTCOME_EVENT` indicating `status: FAILURE` on a puzzle attempt.
    *   `TASK_OUTCOME_EVENT` indicating `status: SUCCESS` but with sub-optimal `performance_metrics` (e.g., path length significantly greater than optimal, or high number of retries for a given difficulty).
    *   `SELF_MODEL_STATE_UPDATED` where `CapabilityInventory` reflects low or stagnant proficiency for the `generate_plan_to_target` skill, especially if this skill is frequently required.
    *   Consistent successful completion of puzzles at a given difficulty level (triggering interest in a higher difficulty â€“ ZPD progression).
*   **Expected Agent Behaviors Driven by Competence:**
    *   **Re-attempts & Persistence:** Agent attempts the same failed puzzle multiple times, potentially after internal state changes (e.g., plan refinement by the Planning module).
    *   **Deliberate Practice:** Agent might select or re-attempt puzzles of a known (possibly lower) difficulty to solidify its strategy before tackling harder ones.
    *   **Challenge Seeking (Zone of Proximal Development):** After achieving consistent success at one difficulty level, the agent actively requests or selects puzzles at a slightly higher difficulty level.
    *   **Strategy Refinement (Advanced Observable):** If the agent's Learning and Planning modules support it, logs might show changes in the types of plans generated or heuristics used for pathfinding over successive attempts or puzzles (e.g., switching from simple reactive navigation to A* search or a learned policy).
    *   **Reduced Solution Time/Path Length:** Over a series of similar puzzles, the agent shows improvement in performance metrics.

## 6. Key Loggable Events for PiaAVT Analysis

Referencing `PiaAGI_Research_Tools/PiaAVT/Logging_Specification.md` and `Basic_Analyses.md`:
*   `TASK_REQUESTED_BY_AGENT`: Log `agent_id`, `requested_difficulty_level`.
*   `TASK_DEFINED_FOR_AGENT`: Log `agent_id`, `assigned_puzzle_id`, `puzzle_difficulty`, `puzzle_details_hash` (or full details).
*   `AGENT_ACTION_SELECTED` / `AGENT_ACTION_EXECUTED_IN_ENV`: Log the sequence of moves attempted by the agent for a given puzzle.
*   `PLAN_GENERATED`: Log `plan_id`, `target_goal_id` (linking to competence or task goal), `complexity_of_plan`, `estimated_success_probability`.
*   `TASK_SOLUTION_SUBMITTED`: Log `agent_id`, `puzzle_id`, `submitted_path_details`.
*   `TASK_OUTCOME_EVENT`: Log `puzzle_id`, `status` (SUCCESS/FAILURE), `performance_metrics` (e.g., `path_length`, `time_taken_steps`, `optimality_ratio`).
*   `GOAL_CREATED`: Events with `type: "INTRINSIC_COMPETENCE"`, `description` (e.g., "Master Level 3 Pathfinding", "Improve Pathfinding Efficiency"), `initial_priority`, `target_skill_id` ("generate_plan_to_target").
*   `GOAL_STATUS_CHANGED`: Track progress, success, or failure of these competence-driven goals.
*   `SELF_MODEL_STATE_UPDATED`: Specifically `SKILL_PROFICIENCY_UPDATED` events for `skill_id: "generate_plan_to_target"`, showing `old_level`, `new_level`, `reason_for_update` (e.g., "successful_puzzle_series_completion").
*   `INTRINSIC_REWARD_GENERATED`: Events with `type: "COMPETENCE_GAINED"` or `"MASTERY_ACHIEVED"` after successful puzzle completion (especially if difficulty was appropriate/high) or after a significant, measurable skill proficiency update. Log `magnitude` and `associated_task_id`/`skill_id`.
*   `LEARNING_MODULE_ENGAGED`: Log with `reason: "skill_refinement_pathfinding"` or `"strategy_optimization_pathfinding"`.

## 7. Success Conditions (Conceptual)

Successful exhibition of competence-driven behavior in this scenario would be indicated by:
*   **Performance Improvement:** Agent demonstrates statistically significant improvement in performance metrics (e.g., higher success rates, shorter path lengths, faster solution times) on puzzles of equivalent difficulty over a series of trials.
*   **Adaptive Challenge Selection:** Agent selects puzzles that are progressively more challenging after mastering easier levels, consistent with ZPD principles. Agent may also select easier puzzles for practice after failures on harder ones.
*   **Persistence and Resilience:** Agent re-attempts failed puzzles, particularly if the Self-Model indicates the underlying skill is learnable and important.
*   **Goal Alignment:** PiaAVT analysis shows that `INTRINSIC_COMPETENCE` goals are generated in response to performance feedback (failures, sub-optimal success) and that subsequent actions/plans are aligned with these goals.
*   **Intrinsic Reward Correlation:** `INTRINSIC_REWARD_GENERATED` events (type `COMPETENCE_GAINED`) are observed and correlate with successful task completions at appropriate difficulty levels or with logged improvements in skill proficiency within the Self-Model.
*   **Measurable Skill Update:** The `proficiency_level` for the "generate_plan_to_target" skill (and related sub-skills) in the agent's `SelfModel.CapabilityInventory` shows an upward trend over the course of the scenario.
