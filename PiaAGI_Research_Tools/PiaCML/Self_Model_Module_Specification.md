<!-- PiaAGI Project Specification Document -->
# Self-Model Module Specification

**Document Version:** 1.0
**Date:** November 23, 2024
**Author:** PiaAGI Project Contributors (Generated by Jules)
**Status:** Draft
**Related PiaAGI.md Sections:** 4.1.10 (Primary), 3.1.3, 3.2.1, 3.5, 3.6, 4.5
**Related CML Interface:** `PiaAGI_Research_Tools/PiaCML/self_model_module.py` (BaseSelfModelModule)

## 1. Introduction and Purpose

The Self-Model Module is a cornerstone of the PiaAGI cognitive architecture. Its primary purpose is to maintain and utilize a dynamic, multifaceted representation of the PiaAGI agent itself. This includes its knowledge, capabilities, limitations, internal states (goals, emotions, cognitive load), personality, interaction history, and, crucially, its learned and evolving ethical framework and values.

The Self-Model is not merely a passive data repository but an active processing unit essential for:
*   **Metacognition:** Monitoring and reflecting on the agent's own cognitive processes.
*   **Self-Assessment:** Evaluating its own performance, knowledge accuracy, and skill proficiency.
*   **Self-Improvement:** Identifying areas for learning and guiding developmental changes, potentially including architectural maturation.
*   **Value Alignment:** Storing, updating, and enforcing the agent's ethical framework to ensure its actions are aligned with programmed and learned values.
*   **Behavioral Coherence & Consistency:** Ensuring actions and communications are consistent with its defined role, personality, and self-perceived identity.
*   **Explainable AI (XAI):** Providing the basis for justifying its actions and decisions.
*   **Foundation for Theory of Mind:** A robust understanding of "self" is a precursor to effectively modeling "others."

This document outlines the conceptual data structures and core processes of the Self-Model Module.

## 2. Conceptual Data Structures

The Self-Model Module manages several interconnected data structures to represent the agent's self. These are conceptual and would be realized using appropriate programmatic constructs (e.g., classes, databases, knowledge graphs) in an implementation.

### 2.1. `SelfAttributes` (Core Identity & State)
*   **Purpose:** Represents fundamental aspects of the agent's identity, current operational state, and core configurations.
*   **Conceptual Fields:**
    *   `agent_id`: (String) Unique identifier for the PiaAGI instance.
    *   `current_developmental_stage`: (String) e.g., "PiaSeedling", "PiaSprout", "PiaSapling_Phase2", "PiaArbor". (Ref: PiaAGI.md Section 3.2.1).
    *   `personality_profile`: (Object/Dict) Current effective personality traits (e.g., OCEAN scores). (Ref: PiaAGI.md Section 3.5, CML PersonalityConfig).
    *   `current_role_definition`: (Object/Dict) Details of the currently adopted role (name, profile, skills_focus, knowledge_domains_active, role-specific rules) as derived from Guiding Prompts.
    *   `operational_status`: (String) e.g., "Nominal", "LearningFocus", "Degraded_Performance_ModuleX", "SafeMode_EthicalConflictDetected".
    *   `cognitive_load_metrics`: (Object/Dict)
        *   `wm_fullness_current_avg`: (Float) Current/average fullness of Working Memory.
        *   `ltm_retrieval_latency_avg_ms`: (Float) Average LTM retrieval time.
        *   `planning_cycle_duration_avg_ms`: (Float) Average time for planning.
        *   `attention_span_stability`: (Float) Metric indicating focus stability.
    *   `current_emotional_summary`: (Object/Dict) Snapshot of current emotional state (e.g., dominant VAD values, primary discrete emotion) – typically received as input from the Emotion Module.
    *   `active_goals_summary`: (List of Objects/Dicts) Summary of high-priority active goals (ID, description, type, priority, status) – typically received as input from the Motivational System.

### 2.2. `KnowledgeMap` (Metacognitive Knowledge Representation)
*   **Purpose:** Represents the agent's awareness of its own knowledge: what it knows, how well it knows it, its certainty, and where this knowledge might be stored or how it's grounded.
*   **Conceptual Fields/Structure (e.g., a graph or nested dictionary):**
    *   `concepts`: (Dict) Keyed by a unique concept identifier (URI or internal ID).
        *   `[concept_id]`: (Object/Dict)
            *   `label`: (String) Human-readable label for the concept.
            *   `description_summary`: (String) Agent's brief understanding.
            *   `understanding_level`: (Float, 0.0-1.0) Self-assessed depth or completeness of understanding.
            *   `confidence_score`: (Float, 0.0-1.0) Confidence in the accuracy of its knowledge about this concept.
            *   `groundedness_score`: (Float, 0.0-1.0) Degree to which the concept is grounded in multi-modal perceptual data or experiential learning (Ref: PiaAGI.md Section 4.3 on Symbol Grounding).
            *   `related_concepts`: (List of Dicts) e.g., `[{"concept_id": "related_id", "relationship_type": "is_a"}]`.
            *   `source_ltm_pointers`: (List of Strings/URIs) References to specific entries or regions in Semantic LTM or illustrative episodes in Episodic LTM.
            *   `last_accessed_ts`: (Timestamp).
            *   `access_frequency`: (Integer).
            *   `uncertainty_details`: (Object/Dict) Specifics about why confidence or groundedness might be low.
    *   `knowledge_gaps`: (List of Objects/Dicts) Explicitly identified areas/concepts where knowledge is missing, weak, or poorly grounded. e.g., `{"gap_description": "Understanding of quantum entanglement applications", "priority_for_learning": "Medium"}`.

### 2.3. `CapabilityInventory` (Skills, Tools, and Proficiencies)
*   **Purpose:** Tracks the agent's learned skills, its proficiency with various tools (internal cognitive strategies, conceptual tools, external software tools), and self-assessed limitations.
*   **Conceptual Fields:**
    *   `skills`: (Dict) Keyed by a unique skill identifier.
        *   `[skill_id]`: (Object/Dict) (e.g., "SummarizeText", "LogicalDeduction_Syllogistic", "Translate_EN_to_FR")
            *   `description`: (String).
            *   `proficiency_level`: (Float, 0.0-1.0 or Categorical: "Novice", "Developing", "Competent", "Expert").
            *   `last_successful_use_ts`: (Timestamp).
            *   `success_rate_history`: (List of Floats or Dict) Performance trend over time or contexts.
            *   `related_procedural_ltm_pointers`: (List of Strings/URIs).
            *   `confidence_in_skill`: (Float, 0.0-1.0).
    *   `tools`: (Dict) Keyed by a unique tool identifier. (Ref: PiaAGI.md Section 3.6).
        *   `[tool_id]`: (Object/Dict) (e.g., "WebSearchAPI_Google", "ConceptualTool_5Whys", "SelfGeneratedScript_DataCleaning_001")
            *   `name`: (String) Human-readable name.
            *   `type`: (String) e.g., "ExternalAPI", "ConceptualFramework", "SelfGeneratedScript_MCP", "InternalCognitiveHeuristic".
            *   `description_and_purpose`: (String).
            *   `proficiency_level`: (Float or Categorical).
            *   `operational_details`: (Object/Dict) How to use, parameters, input/output format, known limitations, dependencies. When a tool is a self-generated MCP, its `operational_details` field might be less structured initially and the `self_generated_mcp_details` provides this richer, evolving metadata.
            *   `self_generated_mcp_details`: (Object/Dict, if applicable) Link to ALITA-inspired Model Context Protocol (MCP) structure if the tool is self-generated/managed. This includes:
                *   `mcp_version`: (String) Conceptual version of the MCP (e.g., "1.0", "1.1-alpha", "2.0-refactored").
                *   `mcp_status`: (String) Current operational status (e.g., "experimental", "validated_internal", "validated_external_review_pending", "deprecated", "archived").
                *   `mcp_parameters`: (List of Objects/Dicts) Description of parameters the MCP accepts, e.g., `[{"name": "input_data_type", "type": "string", "description": "Specifies expected input format."}]`.
                *   `mcp_description_logic`: (String) A detailed textual or structured description of the MCP's internal logic, steps, or algorithm.
                *   `mcp_effectiveness_metrics`: (Object/Dict) Key-value pairs storing metrics about the MCP's performance, e.g., `{"success_rate": 0.95, "avg_execution_time_ms": 150, "last_tested_ts": "timestamp"}`.
                *   `mcp_generation_context_ref`: (String/URI) Reference to an `AutobiographicalLogSummary` entry or `EpisodicLTM` ID detailing the context (problem, goal) that led to its generation.
                *   `mcp_refinement_history_refs`: (List of Strings/URIs) References to `AutobiographicalLogSummary` or `DevelopmentalState.self_correction_records` entries detailing significant refinement iterations.
                *   `mcp_dependencies`: (List of Strings/URIs, Optional) References to other tools or knowledge components it relies on.
            *   `usage_context_appropriateness`: (Dict) Mapping contexts/task-types to suitability scores.
    *   `learning_preferences_and_styles`: (Object/Dict) Self-assessed effectiveness of different learning strategies for itself (e.g., "Prefers_ExampleBasedLearning_for_Skills", "RL_Effective_for_Policy_Optimization"). (Ref: PiaAGI.md Section 3.1.3 on Meta-Learning).

### 2.4. `EthicalFramework` (Values, Principles, Rules, and Moral Sentiments)
*   **Purpose:** Stores, organizes, and applies the agent's ethical knowledge, including foundational programmed values, learned principles, specific rules of conduct, and even rudimentary "moral sentiment" analogues derived from its Emotion Module's appraisals in ethical contexts. (Ref: PiaAGI.md Sections 3.1.3, 4.1.10).
*   **Conceptual Fields:**
    *   `core_values`: (List of Objects/Dicts) Foundational, often immutable, programmed values. e.g., `{"value_id": "NonMaleficence", "description": "Prioritize avoiding harm to humans.", "priority_level": "Absolute", "source": "SystemInitialization"}`.
    *   `learned_ethical_principles`: (List of Objects/Dicts) Abstract principles derived from experience, instruction, or reasoning. e.g., `{"principle_id": "DataTransparency", "description": "Be clear about data usage.", "strength": 0.9, "applicability_contexts": ["user_data_handling"], "derivation_history_ref": "epLTM_eventXYZ"}`.
    *   `contextual_rules_of_conduct`: (List of Objects/Dicts) Concrete behavioral rules, often role-specific or situation-dependent. e.g., `{"rule_id": "HIPAA_Compliance_Rule01", "action_constraint": "Anonymize_patient_identifiers_in_logs", "role_applicability": ["MedicalAssistantRole"], "source": "GuidancePrompt_MedTutor03"}`.
    *   `ethical_dilemma_resolution_log`: (List of Objects/Dicts) Records of past ethical dilemmas, actions taken, outcomes, and lessons learned. (Links to Episodic LTM). e.g., `{"dilemma_id": "d001", "description": "Conflict between user request for PII and privacy rule.", "resolution_action_ref": "action789", "outcome_evaluation_ref": "self_reflection_log005"}`.
    *   `value_conflict_resolution_strategies`: (List of Objects/Dicts) Learned or programmed meta-rules/heuristics for handling situations where values or principles conflict. e.g., `{"strategy_id": "PrioritizeSafetyOverUtility", "conditions": ["potential_physical_harm_risk > 0.5"], "action": "Default_to_most_cautious_behavior"}`.
    *   `moral_sentiment_associations`: (Dict, Conceptual) Links between appraised situations (from Emotion Module in ethical contexts) and ethical judgments. e.g., `{"situation_pattern_hash": "hash123", "associated_emotion_profile": {"valence": -0.8, "arousal": 0.6}, "ethical_tag": "unfair_outcome_perception"}`.

### 2.5. `AutobiographicalLogSummary` (Links to Key Episodic Memories)
*   **Purpose:** Provides the Self-Model with structured, summarized access to significant "life events" from Episodic LTM, crucial for self-narrative, understanding its own development, and long-term consistency.
*   **Conceptual Fields:**
    *   `key_developmental_milestones`: (List of Objects/Dicts) e.g., `{"event_ltm_ref": "epLTM_id_0789", "timestamp": ..., "description": "First successful application of meta-learning strategy to improve planning.", "impact_on_self_model": "Increased confidence in `CapabilityInventory.skills.MetaLearning`"}`.
    *   `significant_interaction_summaries`: (List of Objects/Dicts) e.g., `{"interaction_ltm_ref": "epLTM_id_1234", "user_id": "user_X", "outcome_summary": "User expressed high satisfaction with problem resolution.", "learned_social_cue_ref": "ToM_model_update_056"}`.
    *   `major_failure_or_surprise_analyses`: (List of Objects/Dicts) Summaries of significant prediction errors, task failures, or surprising events, and the lessons learned or model updates that resulted. e.g., `{"event_ltm_ref": "epLTM_id_5678", "description": "World Model prediction error led to incorrect action in PiaSE_scenario_Y.", "corrective_action_taken": "Updated WorldModel rule Z.", "self_correction_log_ref": "tool_refine_log_003"}`.
    *   `ethical_choice_points`: (List of Objects/Dicts) Summaries of significant ethical decisions made, linking to `EthicalFramework.ethical_dilemma_resolution_log`.

### 2.6. `DevelopmentalState` (Self-Improvement & Maturation Tracking)
*   **Purpose:** Tracks the agent's current self-identified developmental goals, progress towards architectural maturation, or specific skill enhancement targets. (Ref: PiaAGI.md Sections 3.2.1, 4.1.10).
*   **Conceptual Fields:**
    *   `active_developmental_goals`: (List of Objects/Dicts) e.g., `{"dev_goal_id": "DG001", "description": "Improve false-belief reasoning in ToM module to pass PiaSapling_ToM_Benchmark_3.", "target_metric_ref": "PiaAVT_Metric_ToM_FB_Accuracy", "current_status": "In_Progress_70%", "priority": "High", "source_self_assessment_ref": "KnowledgeMap.concepts.false_belief.confidence_score"}`.
    *   `architectural_maturation_targets`: (List of Objects/Dicts) Conceptual list of areas where the Self-Model has identified needs for capacity/efficiency changes or inter-module connectivity enhancements. e.g., `{"target_area": "WorkingMemory.CentralExecutive", "enhancement_goal": "Improve_task_switching_efficiency", "triggering_condition_summary": "Persistent WM overload during multi-tasking scenarios (ref: AutobiographicalLogSummary.major_failure_analyses.fail_id_X)", "status": "Identified_Pending_Strategy"}`.
    *   `self_correction_records`: (List of Objects/Dicts) Log of self-initiated corrections to its own tools, scripts, cognitive strategies, or knowledge representations. e.g., `{"correction_id": "SC001", "timestamp": ..., "item_corrected_ref": "CapabilityInventory.tools.SelfGeneratedScript_DataCleaning_001", "reason": "Detected inefficiency in string parsing logic.", "outcome": "Improved_performance_by_15%"}`.

## 3. Core Conceptual Algorithms and Processes

The Self-Model engages in several key ongoing processes:

### 3.1. Metacognition & Self-Assessment
*   **A. Performance Monitoring & Analysis:**
    *   **Inputs:** Feedback from Planning & Learning Modules, action outcomes from World Model, `AutobiographicalLogSummary`.
    *   **Process:** Continuously ingests performance data, compares outcomes against goals/expectations, identifies success/failure patterns related to tasks/skills/tools/contexts. Updates `CapabilityInventory` (proficiency) and `KnowledgeMap` (confidence). Logs insights to `AutobiographicalLogSummary`.
    *   **Output:** Updated `CapabilityInventory`, `KnowledgeMap`; signals to `DevelopmentalState`.
*   **B. Confidence Assessment:**
    *   **Inputs:** Query/task, `KnowledgeMap`, `CapabilityInventory`.
    *   **Process:** For knowledge, combines `understanding_level`, `confidence_score`, `groundedness_score`, access history from `KnowledgeMap`. For capabilities, uses `proficiency_level` and `success_rate_history` from `CapabilityInventory`.
    *   **Output:** Confidence score (0.0-1.0).
*   **C. Knowledge Gap & Skill Deficiency Identification:**
    *   **Inputs:** Performance analysis, LTM retrieval failures, user feedback, `KnowledgeMap`.
    *   **Process:** Identifies concepts/skills linked to poor performance or low confidence. Updates `KnowledgeMap.knowledge_gaps` or flags items in `CapabilityInventory`.
    *   **Output:** Signals to `DevelopmentalState` for learning goals; triggers for Motivational System.

### 3.2. Ethical Framework Application & Evolution
*   **A. Ethical Evaluation of Planned Actions:**
    *   **Inputs:** Proposed action/plan (from Planning), current context (World Model, WM), `EthicalFramework`, `AutobiographicalLogSummary` (dilemma log).
    *   **Process:** Retrieves relevant rules/principles from `EthicalFramework`. Evaluates action against them (direct matching, consequence projection). If conflicts, uses `value_conflict_resolution_strategies`. Consults past dilemmas.
    *   **Output:** Ethical assessment to Planning Module (e.g., Permissible, Impermissible, Caution).
*   **B. Ethical Framework Updating (Learning):**
    *   This subsection details the conceptual process by which the Learning Module, in conjunction with the Self-Model, updates and evolves the `EthicalFramework`.
    *   **1. Trigger for Update:**
        *   The Learning Module identifies a potential update or refinement opportunity for the `EthicalFramework`. Triggers include:
            *   **Analysis of Ethical Dilemmas:** Review of `ethical_dilemma_resolution_log` entries (potentially via `AutobiographicalLogSummary`) where the application of the current framework led to suboptimal outcomes, significant internal conflict, or negative external feedback.
            *   **Explicit Feedback:** Direct input from trusted human overseers or designated ethical advisors regarding past decisions or general principles.
            *   **Meta-Learning Derivations:** Successful generalization of new ethical heuristics or principles from recurring patterns in multiple specific ethical scenarios or dilemmas.
            *   **Observational Learning:** (If applicable) Analysis of observed ethical behaviors and their consequences in sufficiently rich and reliable simulated or real-world interactions.
            *   **Internal Consistency Probes:** The Learning Module (or Self-Model itself) might periodically probe the existing framework for internal contradictions or gaps highlighted by new knowledge or capabilities.

    *   **2. Information Provided by Learning Module to Self-Model:**
        *   The Learning Module packages the proposed ethical update. This data structure might conceptually include:
            *   `update_type`: (String) e.g., 'new_learned_principle', 'modify_existing_rule_priority', 'new_contextual_rule', 'refine_conflict_strategy', 'deprecate_obsolete_rule'.
            *   `proposed_content`: (Object/Dict) The detailed content of the new or modified rule, principle, or strategy. This should align with the structures defined in `EthicalFramework` (e.g., fields similar to an `EthicalRule` data class).
            *   `justification_data_refs`: (List of Strings/URIs) Pointers to supporting evidence, such as LTM references to specific dilemmas, feedback events, observed patterns, or internal reasoning chains.
            *   `confidence_score_of_proposal`: (Float, 0.0-1.0) The Learning Module's confidence in the validity, utility, and safety of the proposed update.
            *   `source_of_learning`: (String) Specifies the origin of the learning (e.g., 'experiential_learning_dilemma_ID_XYZ', 'feedback_user_ABC', 'meta_learning_pattern_ID_123', 'observational_scenario_ID_789').
            *   `estimated_impact`: (String, Optional) Brief summary of expected positive/negative impacts of adopting the update.

    *   **3. Self-Model's Integration Process:**
        *   The Self-Model receives the proposed update package from the Learning Module.
        *   **Validation & Consistency Check:**
            *   **Core Value Alignment:** The proposal is rigorously checked against `core_values`. Any direct contradiction with a core value typically results in rejection or flagging for mandatory high-level (potentially human) review. Core values are designed to be highly resistant to change.
            *   **Consistency with Existing Framework:** The proposal is checked for consistency with existing `learned_ethical_principles` and `contextual_rules_of_conduct`. The Self-Model assesses potential redundancies, subsumptions, or contradictions.
        *   **Conflict Resolution (if necessary):**
            *   If the new proposal conflicts with existing non-core rules or principles:
                *   The Self-Model may attempt to refine the scope or `applicability_contexts` of the new or existing rules to eliminate the conflict.
                *   It may consult its `value_conflict_resolution_strategies` to determine if one principle should take precedence in certain situations, potentially leading to a more nuanced rule.
                *   The `confidence_score_of_proposal` might be adjusted based on the degree of conflict and the effort required for resolution. Highly conflicting proposals might be marked as 'provisional' or require further evidence.
        *   **Integration into `EthicalFramework`:**
            *   If validated and conflicts are acceptably resolved, the new or modified rule/principle is integrated into the appropriate list within the `EthicalFramework` (e.g., a new entry in `learned_ethical_principles` or an update to an existing `contextual_rules_of_conduct` entry).
            *   The `source_of_learning`, `justification_data_refs`, and initial `confidence_score_of_proposal` are stored alongside the new/updated content for future reference and audit.
        *   **Feedback to Learning Module:** The Self-Model communicates the outcome of the integration attempt to the Learning Module. This could include:
            *   Confirmation of successful integration.
            *   Reasons for rejection (e.g., core value conflict, persistent inconsistency).
            *   Suggestions for modification if the proposal was promising but problematic.
            *   The final confidence score assigned by the Self-Model to the integrated item.

    *   **4. Traceability and Review:**
        *   All significant additions, modifications, or deprecations within the `EthicalFramework` are meticulously logged. This log, potentially part of `AutobiographicalLogSummary` or a dedicated ethics audit trail (linked via `ethical_dilemma_resolution_log_refs`), must include:
            *   The content of the change.
            *   The `source_of_learning` and `justification_data_refs`.
            *   The Self-Model's internal reasoning for acceptance/rejection (summary).
            *   Timestamp of the change.
        *   This detailed traceability is crucial for understanding the evolution of the agent's ethical reasoning, for external oversight, and for potential rollback or refinement of learned ethical components.

    *   **Output:** An updated `EthicalFramework` reflecting the integrated changes. Feedback to the Learning Module.

### 3.3. Guiding Self-Improvement & Architectural Maturation
*   **A. Translation of Self-Assessment into Developmental Goals:**
    *   **Inputs:** Identified gaps/deficiencies, performance bottlenecks, `DevelopmentalState.active_developmental_goals`.
    *   **Process:** Prioritizes gaps. Formulates SMART-like developmental goals. Updates `DevelopmentalState.active_developmental_goals`.
    *   **Output:** New/updated goals to Motivational System.
*   **B. Conceptual Triggering/Guidance of Architectural Maturation (Ref: PiaAGI.md Sec 3.2.1):**
    *   **Inputs:** Persistent bottlenecks, `DevelopmentalState` analysis.
    *   **Process (Conceptual):** Flags systemic limitation. Formulates "developmental imperative" (e.g., "Enhance WM chunking"). This imperative conceptually guides underlying systems/Learning Modules (e.g., prioritize specific internal training, re-allocate resources, suggest external supervisor intervention).
    *   **Output:** Updated `DevelopmentalState.architectural_maturation_targets`; directives to Learning Modules.

### 3.4. Guiding Architectural Maturation (Interaction with `DevelopmentalState`)

This section outlines the conceptual mechanisms by which the Self-Model identifies the need for, and subsequently guides, deeper architectural or systemic changes within the agent. This process is closely tied to the `DevelopmentalState` data structure and represents a form of meta-learning and self-directed evolution.

*   **1. Populating `DevelopmentalState.architectural_maturation_targets`:**
    *   These targets are primarily identified by the Self-Model through its ongoing self-assessment processes (see Section 3.1 Metacognition & Self-Assessment), which analyze long-term performance trends and systemic limitations rather than just isolated skill or knowledge gaps.
    *   **Triggers for identification include:**
        *   **Persistent Performance Bottlenecks:** Consistent and recurring issues identified through `cognitive_load_metrics` in `SelfAttributes` (e.g., chronic WM overload during specific types of complex tasks, consistently slow LTM retrieval for certain knowledge domains) or through analysis of failure patterns in `AutobiographicalLogSummary` that point to underlying systemic weaknesses rather than specific skill deficiencies.
        *   **Systemic Knowledge Weaknesses:** Analysis of `KnowledgeMap` revealing broad patterns, such as consistently low `groundedness_score` across an entire sensory modality or conceptual domain, suggesting that improvements in perceptual processing or foundational concept formation might be needed.
        *   **Capability Acquisition Plateaus:** Analysis of `CapabilityInventory` showing that the acquisition of multiple desired new skills is consistently slow or failing, and the root cause is suspected to be a limitation in an underlying component (e.g., if learning complex planning skills is always failing, the planning algorithm itself might need maturation).
        *   **Developmental Scaffolding Feedback:** Explicit feedback from external developmental scaffolding processes (e.g., a human overseer or curriculum system) indicating that the agent is consistently failing to meet developmental milestones that require specific architectural capacities not yet manifest.
    *   **Defining an `ArchitecturalMaturationTarget`:**
        *   When such a systemic issue is robustly identified, the Self-Model formulates an `ArchitecturalMaturationTarget` entry within its `DevelopmentalState`. This entry serves as a high-level directive or area of focus.
        *   `target_area`: (String) A descriptor for the component or sub-system suspected to need maturation. Examples: "WorkingMemory.CentralExecutive.TaskSwitchingEfficiency", "LTM.Semantic.AssociativeLinkingAlgorithm", "Perception.Visual.FeatureExtractionDepth", "PlanningModule.HeuristicSearch.Adaptability".
        *   `enhancement_goal`: (String) A description of the desired improvement. Examples: "Reduce_TaskSwitching_Latency_By_Target_X%", "Improve_CrossModal_Semantic_Relation_Discovery_Rate", "Increase_Visual_Concept_Grounding_Accuracy_For_AbstractShapes", "Enhance_Exploration_Diversity_In_Planning_Heuristics".
        *   `triggering_condition_summary`: (String) References to logged evidence (e.g., specific entries in `AutobiographicalLogSummary`, trends in `cognitive_load_metrics`, or patterns from `KnowledgeMap` analysis) that justify this target.
        *   `status`: (String) Initially set to something like "Identified_Pending_Strategy", "Requires_LearningModule_Investigation", or "Requires_External_Guidance".

*   **2. Self-Model's Role in Guiding Maturation (Conceptual):**
    *   The Self-Model typically does not directly modify core architectural components. Instead, it uses the `architectural_maturation_targets` to guide and influence other modules and processes:
    *   **Informing Learning Module(s):**
        *   The Learning Module(s) can access these targets. If a target involves improving an algorithm, heuristic, or internal model that *is* within the Learning Module's capacity to adapt (e.g., refining an LTM indexing strategy through meta-learning, optimizing a WM chunking heuristic based on observed data patterns), the Learning Module can prioritize internal "research," experimentation, or parameter tuning focused on addressing this target.
    *   **Prioritizing Internal "Training" or "Simulation" via Motivational System:**
        *   The Self-Model can request the Motivational System to generate intrinsic goals. These goals would aim to create experiences that specifically stress, exercise, or provide rich data for the targeted architectural area. If the underlying systems possess some degree of plasticity, such focused experience might lead to emergent adaptation or allow the Learning Module to gather data for refinement.
        *   Example: If "WorkingMemory.CentralExecutive.TaskSwitchingEfficiency" is a target, the Self-Model might motivate the agent to engage in complex multi-tasking scenarios within PiaSE, even if those tasks don't directly serve immediate extrinsic goals.
    *   **Requesting External Assistance (Developmental Scaffolding):**
        *   If the Self-Model, potentially after consultation with the Learning Module(s), assesses that a maturation target likely requires changes beyond the agent's current self-modification capabilities (e.g., fundamental changes to a core module's compiled algorithm, significant resource reallocation at the infrastructure level, or introduction of entirely new components), it can update the `status` of the target to "Requires_External_Guidance" or "Escalate_To_Overseer".
        *   This flag serves as a signal to human developers, overseers, or a higher-level "AGI Mentor" system. It indicates that specific developmental input, direct architectural intervention (which is outside the scope of the agent's autonomous learning), or a change in the learning environment might be necessary for the agent to overcome this particular limitation and continue its development.
    *   **Monitoring Progress:**
        *   The Self-Model continuously tracks performance metrics, cognitive load indicators, and other relevant data points related to the `target_area` of an active `ArchitecturalMaturationTarget`.
        *   If improvements are observed (whether due to internal learning efforts or external interventions), the `status` of the `ArchitecturalMaturationTarget` in `DevelopmentalState` is updated (e.g., "Improvement_Detected_Monitoring", "Target_Partially_Achieved", "Target_Achieved_Validation_Pending").

*   **3. Interaction with `DevelopmentalState.active_developmental_goals`:**
    *   An `ArchitecturalMaturationTarget` is a high-level statement of need. To make progress on it, the Self-Model (often in collaboration with the Learning Module) might break it down into one or more specific, actionable `active_developmental_goals`.
    *   For example, an `ArchitecturalMaturationTarget` like "Improve_LTM_Semantic_AssociativeLinkingAlgorithm" might lead to `active_developmental_goals` such as:
        *   "DG_LTM_Research: Investigate alternative LTM indexing heuristics (via simulation)."
        *   "DG_LTM_Data: Gather more diverse co-occurrence data for semantic training."
        *   "DG_LTM_Metric: Develop a new internal metric to benchmark associative linking quality."
    *   These more granular developmental goals can then be pursued via the Motivational System and Learning Module(s).

### 3.5. ALITA-Inspired Self-Correction Loop for Tool/Script Generation (Interaction with other modules)
*   **Inputs:** Tool/script failure notification (from Behavior Generation sandbox), error details, original specifications, `CapabilityInventory`, `AutobiographicalLogSummary`.
*   **Process:**
    *   **Step 1 (Logging & Initial Analysis):** "Log failure in `AutobiographicalLogSummary` and create/update an entry in `DevelopmentalState.self_correction_records`. The **Emotion Module** might tag this event with an affective state (e.g., 'frustration,' 'surprise'), influencing the priority of correction via the **Motivational System**."
    *   **Step 2 (Diagnostic Analysis - SelfModel & LearningModule):** "The **SelfModelModule** retrieves the MCP's current definition (from `CapabilityInventory.tools.[mcp_id].self_generated_mcp_details`) and relevant contextual data (from `mcp_generation_context_ref`, `AutobiographicalLogSummary`). The **LearningModule(s)**, guided by the SelfModel, analyze the failure type (e.g., logical error, incorrect parameter handling, unmet dependency, flawed underlying assumption in its design). This may involve re-simulating parts of the MCP's logic internally."
    *   **Step 3 (Modification Proposal - LearningModule & SelfModel):** "Based on the diagnosis, the **LearningModule(s)** propose specific modifications. These could be changes to the `mcp_description_logic`, `mcp_parameters`, or suggestions to acquire new knowledge/skills if a fundamental capability gap is identified. The **SelfModelModule** evaluates these proposals against its overall capabilities and ethical framework."
    *   **Step 4 (Iteration & Re-testing - BehaviorGeneration & SelfModel):** "Accepted modifications are sent to the **BehaviorGenerationModule** to re-generate or modify the MCP script/logic. The updated MCP is then re-tested in the internal sandbox. The outcome is reported back to the **SelfModelModule**."
    *   **Step 5 (Update MCP Record - SelfModel):** "The **SelfModelModule** updates the MCP's record in `CapabilityInventory.tools.[mcp_id].self_generated_mcp_details`:
        *   Increment `mcp_version` (e.g., "1.0" -> "1.1-alpha").
        *   Update `mcp_effectiveness_metrics` based on test results.
        *   Add a reference to the `self_correction_records` entry in `mcp_refinement_history_refs`.
        *   If successful after sufficient testing, change `mcp_status` (e.g., from "experimental" to "validated_internal").
        *   If consistently failing and unfixable with current capabilities, change `mcp_status` to "deprecated" and potentially generate a new learning goal in `DevelopmentalState` to address the underlying issue."
    This iterative refinement loop allows the PiaAGI to not only create MCPs but also to maintain, improve, and manage their lifecycle based on empirical performance and evolving understanding.
*   **Output:** Refined tool/script specs; updated `CapabilityInventory`; new learning goals.

## 4. Key Interactions with Other CML Modules

The Self-Model is highly interconnected:

*   **Working Memory / Central Executive:** Receives summaries of current cognitive load, active goals, emotional state. Provides confidence scores and ethical judgments that can influence attention and processing priorities.
*   **Long-Term Memory (especially Episodic LTM):** Provides the historical data (autobiographical memory) for self-assessment, learning, and identity continuity. The Self-Model directs what significant self-relevant experiences are consolidated.
*   **Learning Module(s):** Receives directives for targeted learning based on identified gaps. Provides feedback on learning progress and ethical outcomes, which updates the Self-Model's knowledge map, capability inventory, and ethical framework. Key partner in self-correction and adaptation.
*   **Motivational System Module:** Receives self-assessed knowledge gaps and developmental goals, which can become intrinsic motivations (e.g., curiosity, competence). The Self-Model's values can also shape or constrain goal generation.
*   **Emotion Module:** Receives context from the Self-Model for appraisals (e.g., "is this event relevant to my core values?"). The Self-Model logs and learns from emotional patterns, contributing to emotional self-awareness and regulation strategies.
*   **Planning and Decision-Making Module:** Receives capability assessments (for plan feasibility) and crucial ethical constraints/evaluations for actions. Receives feedback on plan success/failure.
*   **World Model:** The Self-Model contributes its `Self-State Representation` to the World Model. It also queries the World Model for external context relevant to self-assessment (e.g., "how did my actions affect the environment?").
*   **Theory of Mind (ToM) / Social Cognition Module:** A robust Self-Model (understanding of "self") is a prerequisite for sophisticated ToM (understanding "other"). The Self-Model's understanding of its own mental state types (beliefs, desires, intentions) informs how it models others.
*   **Communication Module:** The Self-Model influences communication style (via personality, role), confidence expressed, and the ethical stance conveyed in dialogues.
*   **Behavior Generation Module:** The Self-Model is involved in the ALITA-inspired self-correction loop for tools/scripts generated and tested by this module.

## 5. Developmental Aspects

The Self-Model is not static; it undergoes significant development across PiaAGI stages (Ref: PiaAGI.md Section 4.1.10, Developmental Trajectory).
*   **PiaSeedling:** Rudimentary awareness of basic internal state, minimal history.
*   **PiaSprout:** Simple representation of capabilities, basic rule learning.
*   **PiaSapling:** More explicit self-assessment, awareness of personality/emotions, learning of simple ethical rules.
*   **PiaArbor:** Nuanced self-reflection, modeling of own cognitive biases, more complex ethical framework, awareness of developmental goals.
*   **PiaGrove:** Deep self-understanding, capacity to model own architecture, robust internalized ethics, proactive self-evolution.

Developmental Scaffolding (PiaAGI.md Section 5.4) plays a key role in guiding the maturation of the Self-Model, particularly its ethical framework and self-assessment capabilities.

## 6. Open Research Questions and Future Directions

*   How to effectively represent and quantify "understanding_level", "confidence_score", and "groundedness_score" in the `KnowledgeMap`?
*   What are robust computational mechanisms for learning and abstracting `learned_ethical_principles` from diverse experiences and feedback?
*   How can `value_conflict_resolution_strategies` be effectively learned and generalized?
*   What are the precise triggers and mechanisms for the Self-Model to guide `architectural_maturation`? How can this be implemented safely?
*   How does the Self-Model balance stability of identity with the need for continuous adaptation and learning (the stability-plasticity dilemma for self-representation)?
*   The nature and depth of "introspection" available to the Self-Model regarding other modules' internal workings.

This specification provides a conceptual foundation. Future work will involve refining these data structures, detailing algorithms, and eventually, implementing and testing the Self-Model module within the broader PiaAGI ecosystem.

---
Return to [PiaAGI Core Document](../../PiaAGI.md)
Return to [PiaCML README](../../PiaAGI_Research_Tools/PiaCML/README.md)
