# Computational Model Outlines for Intrinsic Motivations

**Document Version:** 1.0
**Date:** 2024-06-02
**Author:** PiaAGI Project Contributors (Generated by Jules)
**Related Documents:** `Motivational_System_Specification.md`, `PiaAGI_Research_Tools/PiaAVT/Conceptual_Motivation_Models.md`

## 1. Introduction

This document provides high-level computational model outlines, including conceptual algorithms and potential mathematical formulations, for the intrinsic motivations of Curiosity and Competence as defined in the `Motivational_System_Specification.md`. These outlines expand upon the "Key Algorithmic Concepts" mentioned in that specification and are intended to guide future concrete implementations within the `ConcreteMotivationalSystemModule` or more advanced motivational modules.

These models draw inspiration from and should be cross-referenced with the details in `PiaAGI_Research_Tools/PiaAVT/Conceptual_Motivation_Models.md`.

## 2. Computational Model for Curiosity/Information Seeking

(Refers to Section 3 of `Motivational_System_Specification.md`)

### 2.1. Intensity Calculation (Conceptual Formula)

Let $I_c$ be the intensity of curiosity for a target $t$.
$I_c(t) = w_n \cdot N(t) + w_p \cdot PE(t) + w_u \cdot U(t) + w_x \cdot X(t) + w_r \cdot R(t, G_{active}) - w_h \cdot H(t)$

Where:
*   $N(t)$: Novelty score of target $t$ (e.g., 0-1). Derived from Perception or LTM comparison.
*   $PE(t)$: Prediction Error magnitude related to $t$ (e.g., 0-1). From World Model.
*   $U(t)$: Uncertainty metric for $t$ (e.g., 0-1, inverse of confidence/groundedness). From Self-Model (KnowledgeMap).
*   $X(t)$: Complexity score of $t$ (e.g., 0-1). From Perception/analysis.
*   $R(t, G_{active})$: Relevance of information about $t$ to currently active high-priority goals $G_{active}$.
*   $H(t)$: Habituation factor for $t$ (increases with exposure without new info gain).
*   $w_n, w_p, w_u, w_x, w_r, w_h$: Configurable or learnable weights.

### 2.2. Algorithmic Outline for Triggering Curiosity Goal

1.  **Monitor Inputs:** Continuously receive data from Perception (novelty, complexity of stimuli), World Model (prediction errors), Self-Model (knowledge gaps, uncertainty).
2.  **Identify Potential Targets:** For each new stimulus, concept with high uncertainty, or significant prediction error, identify it as a potential target $t$ for curiosity.
3.  **Calculate Intensity $I_c(t)$:** Use the formula above.
4.  **Thresholding:** If $I_c(t) > 	heta_{curiosity\_trigger}$ (a configurable threshold):
    a.  Generate a `GOAL_CREATED` event for the Motivational System.
    b.  `goal_type`: `INTRINSIC_CURIOSITY`
    c.  `description`: e.g., "Investigate stimulus S", "Resolve uncertainty about concept C".
    d.  `initial_priority`: Proportional to $I_c(t)$.
    e.  `target_identifier`: $t$.
    f.  `source_trigger_details`: Information about what triggered this (e.g., novelty score, PE details).
5.  **Habituation Update:** Increment habituation counter $H(t)$ for targets that are explored but yield no new significant information gain.

### 2.3. Intrinsic Reward Calculation (Information Gain - Conceptual)

Let $R_{info\_gain}$ be the intrinsic reward.
$R_{info\_gain}(t) = \Delta U(t) + \Delta PE(t) + k \cdot 	ext{NoveltyIntegrated}(t)$
*   $\Delta U(t)$: Change (reduction) in uncertainty for target $t$.
*   $\Delta PE(t)$: Reduction in prediction error related to $t$.
*   $	ext{NoveltyIntegrated}(t)$: Measure of how much new, unpredicted information about $t$ was successfully integrated.
*   $k$: Scaling factor.

## 3. Computational Model for Competence/Mastery

(Refers to Section 4 of `Motivational_System_Specification.md`)

### 3.1. Intensity Calculation (Conceptual Formula)

Let $I_m$ be the intensity of competence motivation for a skill $s$ or task domain $d$.
$I_m(s/d) = w_{pg} \cdot PG(s/d) \cdot 	ext{Imp}(s/d) + w_{sr} \cdot (1 - SR_{trend}(s/d)) + w_l \cdot L(s/d) - w_f \cdot F_{count}(s/d)$

Where:
*   $PG(s/d)$: Proficiency Gap for skill/domain (e.g., $target\_proficiency - current\_proficiency$).
*   $	ext{Imp}(s/d)$: Importance of the skill/domain for active/future goals.
*   $SR_{trend}(s/d)$: Success Rate trend (e.g., 1 if improving, 0 if stable, -1 if declining). $(1 - SR_{trend})$ makes declining trend increase intensity.
*   $L(s/d)$: Perceived Learnability score from Self-Model.
*   $F_{count}(s/d)$: Recent failure count for tasks requiring $s/d$ (acts as a temporary suppressor if too high, representing frustration).
*   $w_{pg}, w_{sr}, w_l, w_f$: Configurable or learnable weights.

### 3.2. Algorithmic Outline for Triggering Competence Goal

1.  **Monitor Performance:** Receive task outcomes (`GOAL_STATUS_CHANGED`, `TASK_STATUS_UPDATE`) and Self-Model assessments (`CapabilityInventory` updates, skill proficiency levels).
2.  **Identify Targets:**
    *   Skills $s$ linked to recent failures or suboptimal performance.
    *   Skills $s$ with a large $PG(s)$.
    *   Tasks $d$ that are slightly above current overall proficiency (ZPD).
3.  **Calculate Intensity $I_m(s/d)$:** Use the formula above.
4.  **Thresholding:** If $I_m(s/d) > 	heta_{competence\_trigger}$:
    a.  Generate a `GOAL_CREATED` event.
    b.  `goal_type`: `INTRINSIC_COMPETENCE`.
    c.  `description`: e.g., "Improve skill S", "Master task domain D".
    d.  `initial_priority`: Proportional to $I_m(s/d)$.
    e.  `target_identifier`: $s$ or $d$.
    f.  `source_trigger_details`: e.g., recent task failure ID, low proficiency score.

### 3.3. Intrinsic Reward Calculation (Proficiency Gain - Conceptual)

Let $R_{skill\_gain}$ be the intrinsic reward.
$R_{skill\_gain}(s) = \Delta P(s) \cdot 	ext{ChallengeFactor}(s) + 	ext{EfficiencyGain}(s)$
*   $\Delta P(s)$: Change (increase) in proficiency for skill $s$.
*   $	ext{ChallengeFactor}(s)$: A measure of the difficulty of the task through which proficiency was gained.
*   $	ext{EfficiencyGain}(s)$: Measurable improvement in task performance (e.g., speed, resource use) due to skill $s$.

This document provides a starting point for more formal computational modeling of these intrinsic motivations.
