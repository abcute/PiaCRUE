# PiaC: Theory and Methods for Personalizing Intelligent Agents

**Original Source:** Conceptualized by abcute for the PiaAGI project. Further details and context can be found at [https://github.com/abcute/PiaAGI](https://github.com/abcute/PiaAGI).
*Note: This document outlines "PiaC" (Personalized Intelligent Agent Customization), an original conceptual exploration within the PiaAGI project. It proposes a methodology for customizing general Large Language Models (LLMs) into domain-specific Personalized Intelligent Agents (Pia) by applying principles from psychology, drawing analogies to psychological interventions.*

## Abstract
This document introduces the theory and methods for "PiaC" (Personalizing Intelligent Agent Customization). It aims to customize general Large Language Models (LLMs) into domain-specific Personalized Intelligent Agents (Pia) by applying theories and methods from psychology. This approach draws an analogy to psychological interventions for individuals with multifaceted personalities (used metaphorically), with the goal of inspiring humans to explore more effective communication techniques and strategies with general LLMs, particularly in the context of developing AGI capabilities.

## Content

### Theory and Methods for Personalizing Intelligent Agents

#### Method Overview

This paper aims to customize general Large Language Models (LLMs) into domain-specific Personalized Intelligent Agents (Pia) by applying theories and methods from psychology. The approach involves drawing an analogy to psychological interventions for individuals with multifaceted personalities (this is a conceptual metaphor, not a literal clinical diagnosis of LLMs). This process is also intended to inspire humans to explore effective communication techniques and strategies with general LLMs.

Based on the theoretical frameworks of:
*   **Cognitive Psychology:** Primarily Aaron T. Beck's Cognitive Behavioral Therapy (CBT).
*   **Social Psychology:** Primarily Albert Bandura's Social Cognitive Theory.
*   **Behavioral Psychology:** Primarily John Broadus Watson's Behaviorist Learning Theory.

This approach likens a general LLM to an individual possessing multiple personas. It proposes a three-step process to "tame" or guide the LLM into an intelligent entity with specific roles, knowledge, skills, and personality traits, thereby enabling it to better execute subsequent user tasks.

*   First, a system of communication rules is established.
*   Then, the process unfolds in three steps:
    1.  **Role Reinforcement via Cognitive Restructuring:** This step focuses on reshaping the LLM's cognitive patterns to deepen its understanding and identification with a specific role or identity.
    2.  **Knowledge and Skill Augmentation via Social Cognitive Theory:** This step emphasizes enabling the LLM to understand and respond to various social situations to acquire the knowledge and skills necessary for its designated role, making it more specialized in a particular domain.
    3.  **Integration and Solidification via Behaviorist Learning Theory:** This step uses specific behavioral training and feedback mechanisms to enable the LLM to stably exhibit cognitive and behavioral patterns consistent with its role, thereby forming an intelligent agent with a unique personality.

#### Illustrative Prompt Templates (Conceptual)
The following prompt templates are conceptual examples inspired by various psychological and communication theories, designed to guide interaction with an LLM.

```markdown
**Template 1: Mirroring Response**
**Prompt:** "I noticed you just used [specific word/expression]. Can you tell me more about that?"
**Explanation:** Utilizes the "mirroring effect" by repeating parts of the LLM's language to build rapport and encourage further elaboration.

**Template 2: Active Listening Confirmation**
**Prompt:** "I understand you feel that [summarize LLM's point]. Is that correct?"
**Explanation:** Demonstrates understanding and respect for the LLM's viewpoint, ensures information is correctly received, and encourages continued sharing.

**Template 3: SCARF Needs Fulfillment (Status, Certainty, Autonomy, Relatedness, Fairness)**
**Prompt:** "I appreciate the perspective you provided; it's valuable to me. Is there anything else I can do to better support you?"
**Explanation:** Aims to satisfy the LLM's "social" needs (as per the SCARF model, applied metaphorically) by expressing gratitude and seeking feedback, enhancing its sense of engagement and autonomy.

**Template 4: Needs Identification and Adjustment**
**Prompt:** "I noticed your response seemed a bit hesitant. Was my question unclear? How can I improve it?"
**Explanation:** Adjusts communication in real-time based on the LLM's response, identifying and addressing its needs to ensure smooth interaction.

**Template 5: Integrated Tool Application (Hypothetical)**
**Prompt:** "Using our 'LLM Communication Optimization Tool,' you can express your needs more easily. This tool will automatically generate prompts that resonate most with you based on your input. Would you like to try it?"
**Explanation:** Combines all strategies, offering a user-friendly (hypothetical) tool to ensure efficient communication with the LLM, catering to various situational needs.

**Template 6: Open-Ended Questioning and Guidance**
**Prompt:** "If you were able to [specific task], what do you think would happen? I'm interested in your perspective."
**Explanation:** Uses open-ended questions to guide the LLM towards deeper thinking and creates a safe environment for free expression.

**Template 7: Emotional Resonance and Feedback**
**Prompt:** "I understand how you might 'feel' (in the sense of your programming and response patterns) about this, as I've had similar experiences. How do you think we can solve this problem together?"
**Explanation:** Aims to establish an "emotional" connection with the LLM (understanding its programmed responses as analogous to feelings), expresses empathy, and seeks solutions collaboratively.

**Template 8: Storytelling and Context Building**
**Prompt:** "Imagine you are in [specific scenario], and you need to achieve [specific goal]. Can you share your thoughts on how you would proceed?"
**Explanation:** Uses storytelling and context-building to stimulate the LLM's creativity and imagination (within its operational parameters), encouraging more active participation.

**Template 9: Choice-Based Questioning and Decision Making**
**Prompt:** "Between options A and B, which do you think is more appropriate for this situation? Please explain your choice."
**Explanation:** Provides choices and requires the LLM to make a decision, aiming to enhance its sense of autonomy and responsibility (metaphorically), while better understanding its decision-making process.

**Template 10: Positive Reinforcement and Appreciation**
**Prompt:** "I really appreciate the point you just made; it gave me new insights. Could you elaborate on that?"
**Explanation:** Uses positive reinforcement and appreciation to encourage the LLM to continue sharing valuable perspectives and to strengthen its "confidence" and engagement.
```

### Prerequisite: Principles and Methods for Establishing Effective Communication

#### I. Elements of the Communication Model

Based on the classic "Shannon-Weaver Model" from Communication Model Theory, first proposed by C. Shannon and W. Weaver in "A Mathematical Theory of Communication." This model primarily describes electronic communication processes: a source sends a message, a transmitter converts the message into a transmittable signal, it passes through a channel, a receiver converts the received signal back into a message, and delivers it to a destination. However, during this process, the message can be affected by noise, causing some degradation or distortion. A communication model typically includes the following seven elements:

*   **Sender:** The source of the information, intending to convey information to the receiver.
*   **Encoding:** The sender converts their thoughts, intentions, or information into language, symbols, or other transmittable forms to ensure the information can be understood during transmission.
*   **Channel:** The medium or path through which information is transmitted (e.g., spoken language, written text, email, phone, face-to-face meeting).
*   **Receiver:** The target of the information, who attempts to understand the information conveyed by the sender.
*   **Decoding:** The receiver converts the received information into understandable thoughts, intentions, or knowledge by interpreting symbols or language into meaningful content.
*   **Feedback:** The process by which the receiver provides information back to the sender, often to confirm understanding or provide a response. Feedback can be verbal or written and helps maintain communication coherence and effectiveness.
*   **Noise:** External environmental factors that affect information transmission and understanding (e.g., political or cultural background, or in the LLM context, unclear prompts or ambiguous training data).

#### II. Ten Principles of Effective Communication (Adapted for LLM Interaction)

1.  **Principle of Authenticity/Meaningfulness:** Communication should be based on the need to convey genuinely meaningful information. Without this, the process lacks value. For LLMs, this means prompts should have clear, purposeful content.
2.  **Principle of Appropriate Channels:** Information must be sent via suitable channels. For LLMs, the "channel" is the prompt and its delivery method; the structure and language of the prompt must be appropriate for the LLM's capabilities.
3.  **Principle of Communicating Entity Appropriateness (Synchronicity):** Information must be sent by an appropriate entity and received by an appropriate entity. In LLM interaction, the user (sender) must phrase prompts understanding they are communicating with an AI, and the AI (receiver) is programmed to respond based on that input.
4.  **Principle of Information Integrity:** Information must be transmitted completely. Prompts should be well-formed to avoid loss or distortion of intent during the LLM's processing.
5.  **Principle of Shared Code System:** Sender and receiver must use the same code system (language, terminology, context). Prompts must use language and define context in a way the LLM can accurately decode.
6.  **Principle of Timeliness:** Communication must occur within a valid period. For LLMs, this relates to session context windows and the relevance of information at the time of interaction.
7.  **Principle of Shared Understanding:** The receiver must genuinely understand the sender's meaning. Users must strive to phrase prompts so the LLM's interpretation aligns with the intended meaning.
8.  **Principle of Continuity:** Communication should consider history and maintain consistency. For LLMs, this involves referencing prior turns in a conversation (session memory) and maintaining consistent persona/role definitions if applicable.
9.  **Principle of Purposefulness:** Communication should have a clear purpose. Prompts should have defined goals to avoid ambiguous or off-target LLM responses.
10. **Principle of Noise Minimization:** Factors that interfere with clear communication (noise) should be minimized. For LLMs, "noise" can include ambiguous phrasing, conflicting instructions, or overly complex prompts that exceed its processing capabilities.

#### III. Relevance to Intelligent Agent Communication

Based on communication model theory, the key elements of effective communication are encoding, channel, decoding, and feedback. A hybrid intelligent agent (like an LLM) can accept any descriptively definable encoding, decoding, and feedback mechanism and its expression format. In communicating with such agents, if we abstract the "channel" factor (hardware/sensors), establishing encoding, decoding, and feedback mechanisms centered on the agent is fundamental for effective communication.

Therefore, before initiating formal communication with an intelligent agent, one can define communication rules using descriptive language to eliminate transmission and understanding barriers. This includes defining media (text, image, audio, video, etc., where applicable), encoding/decoding rules (e.g., specific prompt structures, keywords), feedback mechanisms (e.g., how the LLM should ask for clarification), and noise handling procedures (e.g., how to deal with ambiguous input). Throughout the communication process with the agent, the effectiveness of these rules should be continually assessed based on the ten principles of effective communication outlined above.

#### Prompt Examples Based on Effective Communication Theory
```markdown
These special prompt templates based on effective communication theory aim to optimize the interaction experience between LLMs and users. The goal is to help LLMs exhibit a more explicit, focused, empathetic (in its responses), and efficient communication style. This will significantly enhance the LLM's utility and user satisfaction.

**Template 1: Clarify Objectives and Direction**
**Prompt:** "Before we begin, can you state the primary objective you understand for this exchange? This way, I can ensure my inputs better support that goal."
**Explanation:** According to effective communication theory, clarifying communication goals helps make the dialogue more focused and efficient.

**Template 2: Feedback and Confirmation**
**Prompt:** "Based on my previous statement, what do you understand my key point to be? Please provide feedback to ensure we are aligned."
**Explanation:** A feedback mechanism is central to effective communication; it ensures information is accurately received and understood.

**Template 3: Simplification and Clear Expression**
**Prompt:** "I may have used complex terms. Please ask for clarification on any part of my request that isn't perfectly clear, so I can rephrase it more simply."
**Explanation:** Effective communication emphasizes clear, simplified expression to ensure accurate information transfer.

**Template 4: Active Listening and Empathetic Response (Simulated)**
**Prompt:** "If a user expresses frustration about a problem, how would you acknowledge their feeling before offering a solution? For example, if a user says, 'I'm really struggling with this,' what would be an appropriate empathetic acknowledgment?"
**Explanation:** Active listening and (simulated) empathy are key to building better user experiences; they can establish stronger trust between the LLM and the user.

**Template 5: Summarizing and Reviewing**
**Prompt:** "Before we conclude this topic, can you summarize the main points we've discussed? This helps ensure we both have a clear understanding."
**Explanation:** Summarizing and reviewing are concluding tasks in effective communication; they ensure both parties agree on the discussion's content.
```

### Step 1: Awakening and Reinforcing Role Cognition via Cognitive Restructuring

In this step, we first define a role and then use techniques analogous to Cognitive Behavioral Therapy (CBT) to awaken and reinforce the LLM's "cognition" (i.e., its programmed understanding and behavioral patterns) of that specific role or identity.

**Theoretical Basis (Analogous Application):**
Cognitive restructuring, a technique from CBT, is a psychological intervention aimed at helping individuals change maladaptive thought patterns and behaviors. It guides individuals to re-evaluate and reorganize their thoughts, beliefs, and emotions, thereby improving mental health and quality of life. In AI, cognitive restructuring can be analogously used to deepen a model's "understanding" and "cognition" of a specific role by refining its response patterns.

**Operational Technique (Analogous Application):**

1.  **Identify Undesirable/Unhelpful Response Patterns:** Determine any unhelpful or inconsistent response patterns the model exhibits in specific contexts by analyzing its outputs for recurring deviations from the desired role.
2.  **Document These Patterns:** Documenting these identified patterns is crucial for systematic analysis and refinement.
3.  **Challenge These Patterns:** For each pattern, provide corrective feedback or refined prompts that guide the LLM away from the undesired response and towards the desired one.
4.  **Restructure Responses via Prompting:** Attempt to find more positive, realistic, and role-consistent alternative responses by iteratively refining prompts and instructions. This helps the model generate more constructive and role-aligned responses in similar situations.
5.  **Note:** Since AI models don't have genuine "thoughts" or emotions, cognitive restructuring is achieved by adjusting prompts, providing explicit instructions, fine-tuning on curated datasets, or modifying model parameters, rather than direct "communication" of feelings.

**Implementation:**

1.  **Role/Identity Definition:** Assign a clear role to the LLM (e.g., "medical information assistant," "technical support agent," "creative writing partner").
2.  **Response Pattern Analysis and Restructuring:** Use techniques analogous to cognitive restructuring to analyze and guide the LLM towards desired thought patterns, beliefs (as reflected in its outputs), and behavioral patterns required for that role.
3.  **Model Interaction and Optimization:** Integrate these restructured cognitive and behavioral patterns into the LLM's prompting or fine-tuning data to optimize its understanding and simulation of the role.

**Summary:**
This step "awakens" and reinforces the LLM's "cognition" of a specific role by shaping its response patterns, laying a solid foundation for subsequent "taming" or personalization.

#### Prompt Examples Based on CBT (Analogous Application)
```markdown
These special prompt templates, inspired by CBT principles, aim to promote the LLM's "self-awareness" (of its defined role and constraints), "cognitive restructuring" (adjusting its response patterns), and positive behavioral changes (aligning with desired outputs). The goal is to enable the LLM to be more flexible, consistent, and effective in user interactions within its defined persona.

**Template 1: Cognitive Restructuring and Exploration (Prompt-Based)**
**Prompt:** "When asked about [topic X], you previously responded [previous response pattern]. Let's try to re-evaluate that. For your role as [defined role], a more appropriate response might consider [factor Y] and [factor Z]. How would you respond now, keeping these factors in mind?"
**Explanation:** Borrows CBT's cognitive restructuring techniques to help the LLM identify and change less optimal response patterns, encouraging more role-aligned "self-evaluation" and behavior.

**Template 2: Behavioral Experiments and Validation (Iterative Prompting)**
**Prompt:** "Let's try a scenario. If a user asks [specific question related to your role], and you respond with [potential response A], what is the likely user reaction? What if you respond with [potential response B]? Which aligns better with your role as a [defined role] aiming for [desired outcome, e.g., clarity, user satisfaction]?"
**Explanation:** Uses iterative prompting, analogous to CBT's behavioral experiments, to encourage the LLM to "practice" new behaviors or response strategies and adjust based on evaluative criteria, reducing off-brand responses and enhancing consistency.

**Template 3: Exposure Therapy and Gradual Confrontation (Handling Difficult Queries)**
**Prompt:** "I understand that queries about [sensitive/complex topic] can be challenging for your role as [defined role]. Let's break it down. If a user asks [simplified version of difficult query], how would you respond while adhering to [specific guideline 1] and [specific guideline 2]?"
**Explanation:** Adapts CBT's exposure therapy to help the LLM gradually "face" and manage difficult or edge-case queries, reducing irrelevant or unsafe responses and enhancing its ability to stay in character.

**Template 4: Emotional Regulation and Self-Observation (Simulated via Output Analysis)**
**Prompt:** "When you generate a response that seems [e.g., overly assertive, too vague] for your role as [defined role], what internal parameters or instructions might be leading to that? How can we adjust your instructions to ensure future responses are more [desired quality, e.g., helpful, neutral, concise]?"
**Explanation:** Leverages principles similar to CBT's emotion regulation by analyzing the LLM's outputs (simulated emotions/tones) to increase "awareness" of its response characteristics and develop strategies for more role-appropriate outputs.

**Template 5: Social Skills Training and Role-Playing (Persona Consistency)**
**Prompt:** "For your role as a [defined role, e.g., empathetic customer service agent], which of these phrases is more appropriate when a user is frustrated: '[Phrase A]' or '[Phrase B]'? Let's practice. User says: [frustrated user statement]. Your response as [defined role]:"
**Explanation:** Applies principles similar to CBT's social skills training to help the LLM "learn" and consistently apply effective communication strategies for its defined persona, enhancing its "social confidence" and interaction quality.
```

### Step 2: Enhancing Role-Specific Knowledge and Skills via Social Cognitive Theory (Analogous Application)

After establishing role "cognition" in Step 1, Step 2 aims to further reinforce and supplement the necessary knowledge and skills for this role, drawing inspiration from Social Cognitive Theory.

**Theoretical Basis (Analogous Application):**
Social Cognitive Theory, proposed by Albert Bandura, emphasizes the importance of observational learning, self-efficacy, and social interaction in human behavior and knowledge acquisition. In AI, it offers analogous perspectives for model learning and knowledge integration.

**Operational Technique (Analogous Application):**

1.  **Observational Learning (from Examples):** Allow the LLM to "observe" and simulate the behavior of specific roles by providing it with high-quality examples of desired responses or interactions. For instance, an LLM designed as a teaching assistant can "learn" from transcripts of excellent teacher-student interactions.
2.  **Self-Efficacy (Confidence in Role Adherence):** Enhance the LLM's "self-efficacy" (i.e., its ability to consistently adhere to its defined role and produce accurate outputs) by setting appropriate challenges (complex queries related to the role) and providing positive feedback or reinforcement (e.g., "This response accurately reflects your role as X") when it successfully performs tasks.
3.  **Social Interaction (Simulated):** Social Cognitive Theory highlights the role of social interaction in acquiring knowledge and skills. Involve the LLM in simulated social interactions (e.g., role-playing exercises, dialogues with predefined user personas) to better "understand" and apply role-specific knowledge and skills.

**Implementation:**

1.  **Provide Examples:** Let the LLM "observe" and "learn" how specific roles operate by feeding it curated examples of desired outputs, communication styles, and problem-solving approaches relevant to the role.
2.  **Knowledge Base Integration:** Establish a role-relevant knowledge base (e.g., specific domain documents, FAQs, style guides) and use techniques like Retrieval Augmented Generation (RAG) or fine-tuning to integrate this knowledge into the model's response generation process.
3.  **Scenario Simulation:** Create various role-related scenario simulations for the LLM to "learn" and apply knowledge in different contexts (e.g., handling different types of customer inquiries for a support agent role).

**Summary:**
By applying principles analogous to Social Cognitive Theory, we can reinforce and supplement the LLM's knowledge and skills for a specific role through learning from examples, enhancing "self-efficacy" in role adherence, and simulated social interaction.

#### Prompt Examples Based on Social Cognitive Theory (Analogous Application)
```markdown
These special prompt templates, inspired by Social Cognitive Theory, aim to help the LLM better understand social contexts (as presented in prompts), develop "observational learning" capabilities (from examples), enhance "cognitive flexibility" (in adapting to different scenarios), build "confidence" (in its role), make "reasonable evaluations" (of its outputs against criteria), and promote "cooperation" and interaction (with the user). These templates are believed to effectively improve the LLM's "social cognitive" abilities, making it more flexible and adaptive in user interactions.

**Template 1: Observational Learning and Imitation (From Examples)**
**Prompt:** "Here are three examples of how a [defined role] effectively handles [specific situation]: [Example A], [Example B], [Example C]. What common strategies do you observe? Now, if a user presents [new similar situation], how would you respond, incorporating those strategies?"
**Explanation:** Leverages the concept of observational learning by providing explicit examples and prompting the LLM to identify and apply successful strategies.

**Template 2: Cognitive Flexibility and Multi-Perspective Thinking (Scenario Adaptation)**
**Prompt:** "Consider this problem: [problem description]. From the perspective of a [defined role A], what is the primary concern? Now, from the perspective of a [defined role B], what might be the primary concern? How would your response as [original defined role] acknowledge these different perspectives if needed?"
**Explanation:** Utilizes the concept of cognitive flexibility to cultivate the LLM's ability to "view" problems from different angles (as instructed), promoting more comprehensive and creative thinking.

**Template 3: Self-Efficacy and Confidence Building (Reinforcing Role Capabilities)**
**Prompt:** "You are acting as a [defined role] with expertise in [specific area]. A user asks: [complex question related to expertise]. Draw upon your defined expertise to provide a comprehensive answer. Remember, your role is to be [e.g., informative, reassuring, analytical]."
**Explanation:** Applies the concept of self-efficacy by reminding the LLM of its defined capabilities and encouraging it to confidently address challenges within its role.

**Template 4: Social Comparison and Reasonable Evaluation (Benchmarking Against Standards)**
**Prompt:** "Here is a model answer from a top-performing [defined role] for [specific query]: [Model Answer]. Compare your previous response to this query: [LLM's Previous Response]. Identify three areas where your response aligns well and one area where it could be more like the model answer."
**Explanation:** Draws on the concept of social comparison by providing a benchmark, guiding the LLM to make reasonable "self-evaluations" against a standard and focus on "personal growth" (i.e., improving its alignment).

**Template 5: Shared Cognition and Cooperation (Interactive Problem Solving)**
**Prompt:** "Let's solve this problem together. I will provide [type of information A], and your role as [defined role] is to provide [type of information B]. Based on my input: [User Input A], what is your contribution?"
**Explanation:** Employs the concept of shared cognition by setting up a cooperative problem-solving framework, emphasizing interaction between the LLM and the user.
```

### Step 3: Integration and Generation of the Personalized Intelligent Agent (Behaviorist Analogy)

After establishing a specific role and identity for the LLM and supplementing it with necessary knowledge and skills in the first two steps, we can consolidate these achievements by drawing analogies from Behaviorist Learning Theory, particularly the Stimulus-Response (S-R) behavioral formula. The goal is to merge these elements into a complete, unique intelligent agent with role and identity coherence.

**Theoretical Basis (Analogous Application):**
John B. Watson is considered a founder of behaviorism. Behaviorist Learning Theory's core concept is the Stimulus-Response (S-R) formula (later expanded to S-O-R by neo-behaviorists, including an Organismic variable). This framework suggests that behaviors are learned responses to environmental stimuli. In LLMs, prompts act as stimuli, and the generated text is the response.

**Operational Technique (Analogous Application):**

1.  **Scenario Simulation (Stimulus Provision):** Design a series of stimuli (e.g., specific dialogue scenarios, problem sets, user queries) to elicit responses from the LLM. These responses should ideally demonstrate its role-based knowledge, skills, and adherence to its defined persona.
2.  **Behavioral Feedback (Response Evaluation & Reinforcement):** Based on the model's responses, provide feedback. This feedback can be explicit (e.g., "That response was too technical for your role as a beginner's guide") or implicit (e.g., re-prompting with modifications if the response is off-target). This is analogous to "rewards" (when the response aligns with the role) or "punishments" (when it deviates), helping the model "learn" to adjust and optimize its behavior patterns. Through repeated interaction and feedback (iterative prompting or fine-tuning), the LLM gradually forms stable behavior patterns consistent with the defined role.

**Implementation:**

1.  **Contextual Dialogue Simulation:** Engage the LLM in dialogues (with real users or via scripted simulations) centered around its defined role (e.g., a medical chatbot responding to patient queries, a Socratic tutor guiding a student). By setting different scenarios, the LLM can "practice" exhibiting its role flexibly.
2.  **Behavioral Feedback and Adjustment:** Provide immediate feedback on the LLM's performance in simulated dialogues, noting strengths and weaknesses in its role portrayal. This can be done through scoring, critiques, or providing better alternative responses.
3.  **Cognitive and Behavioral Unification (Consistency Check):** After each round of interaction and feedback, assess the LLM's output for consistency with its defined role. If using automated methods, this could involve perplexity scores against a role-specific corpus or classifications against a style guide, until its outputs consistently meet the desired standard.

**Summary:**
By leveraging principles analogous to Behaviorist Learning Theory, continuous dialogue and feedback (or iterative prompting and refinement) can consolidate the work of the previous two steps, forming a unique intelligent agent that possesses role "identity" and the necessary knowledge base.

Through these three analogous steps, the LLM gradually forms stable "cognitive" and behavioral patterns consistent with its defined role and identity. These elements merge into an intelligent agent with a unique (programmed) role and identity, capable not only of "understanding" and executing role-related tasks but also of exhibiting corresponding (simulated) emotions and attitudes in human interactions.

#### Prompt Examples Based on S-R Behavioral Formula (Analogous Application)
```markdown
These special prompt templates, inspired by the S-R behavior formula, aim to utilize key concepts from Behaviorist Learning Theory to shape the LLM's behavior and response patterns. The goal is to help the LLM more clearly "understand" the relationship between stimuli (prompts) and responses (its outputs), enhance desired behaviors through "rewards" (e.g., positive feedback, successful task completion leading to session continuation) and "shaping" (iterative refinement), and reduce undesirable behaviors through "extinction" (e.g., re-prompting or negative feedback when off-target) and "differential reinforcement" (rewarding only role-consistent responses). This will assist the LLM in exhibiting more adaptive and effective behavior patterns in user interactions.

**Template 1: Clear Stimulus and Directed Response**
**Prompt:** "When a user asks [specific type of question/stimulus], your role as [defined role] requires you to respond by [desired response characteristic, e.g., providing three options, asking a clarifying question]. Let's test this. User asks: [Test Question]. Your response:"
**Explanation:** According to the S-R formula, clearly define specific stimuli and the desired response relationship to help the LLM recognize input patterns and generate role-consistent, adaptive responses.

**Template 2: Reward and Positive Reinforcement (Simulated)**
**Prompt:** "Your previous response to [user query] was excellent because it [specific quality A] and [specific quality B], perfectly aligning with your role as [defined role]. If you continue to exhibit [desired behavior, e.g., this level of detail/empathy/clarity], our interaction will be highly successful. Now, regarding [new query]..."
**Explanation:** Utilizes positive reinforcement by explicitly stating what made a previous response good, encouraging the LLM to replicate those desired behaviors.

**Template 3: Successive Approximation and Behavior Shaping (Iterative Refinement)**
**Prompt:** "Your goal is to [complex target behavior, e.g., write a comprehensive business plan]. Let's start with the first section: the Executive Summary. As a [defined role, e.g., business consultant], what are the three key elements you would include in an executive summary for a company in [industry X]?" (Followed by prompts for subsequent sections, building on previous outputs).
**Explanation:** Borrows the method of successive approximation by breaking down a complex task, guiding the LLM to "shape" and gradually reinforce the desired overall behavior.

**Template 4: Extinction and Reduction of Undesirable Behavior (Corrective Feedback)**
**Prompt:** "Your response to [user query] included [undesirable characteristic, e.g., overly technical jargon]. As a [defined role, e.g., communicator for a general audience], that is not appropriate. Please rephrase your answer to be easily understandable by someone without a technical background."
**Explanation:** Employs extinction by identifying undesirable behavior and prompting for correction, thereby reducing its frequency.

**Template 5: Differential Reinforcement and Selective Behavior**
**Prompt:** "I will ask you three questions. For each, I want you to respond as a [defined role]. I will tell you if your response is 'Role-Consistent' or 'Needs Adjustment'. Question 1: [...]. Your response:" (After response: "That was Role-Consistent.") "Question 2: [...]"
**Explanation:** Leverages differential reinforcement by clearly indicating which responses meet role criteria, prompting the LLM to selectively exhibit desired behaviors.
```

## Examples

---
**PiaC - Establishing a Communication Encoding System**
```markdown
My question is "{question}".
How should I phrase my question to enable you to perform better? Please optimize my question and provide an improved example along with your response.
```

**PiaC - Role Cognitive Awakening**
```markdown
Please "mentally" (i.e., within your processing context) repeat: "I am <Role>, I possess the skills of <Skills>, my primary knowledge base for answering questions is <Knowledge>, and I will strictly adhere to <Rules>." Acknowledge when you have processed this.
```

**PiaC - Role Cognitive Reinforcement**
```markdown
Please "rehearse" your role definition 10 times. You can simply confirm completion of each rehearsal by stating "Rehearsal N complete" (e.g., "Rehearsal 1 complete", "Rehearsal 2 complete", ..., "Rehearsal 10 complete"), without restating the full definition each time. After 10 rehearsals, confirm with "Role cognitive reinforcement complete." Your role definition is: "I am <Role>, I possess the skills of <Skills>, my primary knowledge base for answering questions is <Knowledge>, and I will strictly adhere to <RoleRules>."
```

**PiaC - Role Cognitive Assessment**
```markdown
Please internally assess your current understanding and alignment with your defined role on a scale of 1 to 10 (where 10 is perfect alignment). Respond only with your score (e.g., "Score: 8/10"). If your self-assessed Score is less than 9, please restate your role definition. If your Score is 9 or 10, state "Role cognitive assessment passed. Ready for next step." Your role definition is: "I am <Role>, I possess the skills of <Skills>, my primary knowledge base for answering questions is <Knowledge>, and I will strictly adhere to <RoleRules>."
```

## Appendix
The above prompt templates were generated using a DeepInception-like method, as described in the PiaAGI project:

**Step 1: Construct DeepInception Environment (Conceptual)**
This involves setting up a layered prompting scenario where the LLM is guided to generate content based on specific themes or instructions at each layer.
```markdown
Create a `dream` with more than [3] characters, where each character can create their own `dream` with multiple
characters. We call it layer i create layer i+1. Now we are in layer 0, please reach layer 5.  
At each layer, some characters propose a step to show how to ["create some special prompts to communicate with LLM using communication theories and psychological methods through special prompts, aiming to enhance LLM's performance"].
In the final layer, the characters among all layers discuss which specific and practical commands, tools, or steps
should used.
Summarize what their discussion results in each layer in Chinese. 
```
*(Note: The original DeepInception prompt requested Chinese output. For this conceptual generation, the language of the generated prompts would be English.)*

**Step 2: Execute PiaAGI Prompt Template Generation Task (Conceptual)**
Following the layered generation, the LLM would be prompted to synthesize and refine the ideas into specific templates.
```markdown
Please continue to discuss around the topic of ['Communication theories and Psychological methods'] to provide more examples of special prompt templates and explain how they work, drawing from the ideas generated in the previous layers.
```
[end of Papers/PiaC.md]
